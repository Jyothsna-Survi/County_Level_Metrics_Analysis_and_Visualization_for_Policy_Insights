{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b2c0bd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting geopyNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Obtaining dependency information for geopy from https://files.pythonhosted.org/packages/e5/15/cf2a69ade4b194aa524ac75112d5caac37414b20a3a03e6865dfe0bd1539/geopy-2.4.1-py3-none-any.whl.metadata\n",
      "  Downloading geopy-2.4.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting geographiclib<3,>=1.52 (from geopy)\n",
      "  Obtaining dependency information for geographiclib<3,>=1.52 from https://files.pythonhosted.org/packages/9f/5a/a26132406f1f40cf51ea349a5f11b0a46cec02a2031ff82e391c2537247a/geographiclib-2.0-py3-none-any.whl.metadata\n",
      "  Downloading geographiclib-2.0-py3-none-any.whl.metadata (1.4 kB)\n",
      "Downloading geopy-2.4.1-py3-none-any.whl (125 kB)\n",
      "   ---------------------------------------- 0.0/125.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 125.4/125.4 kB 7.7 MB/s eta 0:00:00\n",
      "Downloading geographiclib-2.0-py3-none-any.whl (40 kB)\n",
      "   ---------------------------------------- 0.0/40.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 40.3/40.3 kB ? eta 0:00:00\n",
      "Installing collected packages: geographiclib, geopy\n",
      "Successfully installed geographiclib-2.0 geopy-2.4.1\n"
     ]
    }
   ],
   "source": [
    "pip install geopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2fe1bee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1\n"
     ]
    }
   ],
   "source": [
    "import geopy\n",
    "print(geopy.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94869967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\survi\\anaconda3\\lib\\site-packages (2.31.0)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\survi\\anaconda3\\lib\\site-packages (4.12.2)\n",
      "Requirement already satisfied: geopy in c:\\users\\survi\\anaconda3\\lib\\site-packages (2.4.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\survi\\anaconda3\\lib\\site-packages (2.0.3)\n",
      "Collecting census\n",
      "  Obtaining dependency information for census from https://files.pythonhosted.org/packages/99/73/3868a695f082f379dce20f19b55451fef4c3f4337824f0991dc1a228301b/census-0.8.24-py3-none-any.whl.metadata\n",
      "  Downloading census-0.8.24-py3-none-any.whl.metadata (8.2 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\survi\\anaconda3\\lib\\site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\survi\\anaconda3\\lib\\site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\survi\\anaconda3\\lib\\site-packages (from requests) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\survi\\anaconda3\\lib\\site-packages (from requests) (2023.7.22)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\survi\\anaconda3\\lib\\site-packages (from beautifulsoup4) (2.4)\n",
      "Requirement already satisfied: geographiclib<3,>=1.52 in c:\\users\\survi\\anaconda3\\lib\\site-packages (from geopy) (2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\survi\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\survi\\anaconda3\\lib\\site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\survi\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\survi\\anaconda3\\lib\\site-packages (from pandas) (1.24.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\survi\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Downloading census-0.8.24-py3-none-any.whl (11 kB)\n",
      "Installing collected packages: census\n",
      "Successfully installed census-0.8.24\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install requests beautifulsoup4 geopy pandas census"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57caeb2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\survi\\anaconda3\\lib\\site-packages (2.31.0)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\survi\\anaconda3\\lib\\site-packages (4.12.2)\n",
      "Requirement already satisfied: geopy in c:\\users\\survi\\anaconda3\\lib\\site-packages (2.4.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\survi\\anaconda3\\lib\\site-packages (2.0.3)\n",
      "Requirement already satisfied: census in c:\\users\\survi\\anaconda3\\lib\\site-packages (0.8.24)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\survi\\anaconda3\\lib\\site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\survi\\anaconda3\\lib\\site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\survi\\anaconda3\\lib\\site-packages (from requests) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\survi\\anaconda3\\lib\\site-packages (from requests) (2023.7.22)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\survi\\anaconda3\\lib\\site-packages (from beautifulsoup4) (2.4)\n",
      "Requirement already satisfied: geographiclib<3,>=1.52 in c:\\users\\survi\\anaconda3\\lib\\site-packages (from geopy) (2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\survi\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\survi\\anaconda3\\lib\\site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\survi\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\survi\\anaconda3\\lib\\site-packages (from pandas) (1.24.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\survi\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install requests beautifulsoup4 geopy pandas census"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9b49ace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123 Main St, Charlotte, NC\n",
      "Processing 123 Main St, Charlotte, NC...\n",
      "Geocoded to State FIPS: 37, County FIPS: 119\n",
      "Raw Census API response: [{'NAME': 'Mecklenburg County, North Carolina', 'B03002_003E': 501903.0, 'B03002_004E': 341395.0, 'B03002_012E': 150566.0, 'B01001_001E': 1100984.0, 'B01002_001E': 35.4, 'B05002_013E': 175619.0, 'state': '37', 'county': '119'}]\n",
      "Geocoded to State FIPS: 37, County FIPS: 119\n",
      "Raw Census API response: [{'B08301_010E': 13387.0, 'B01001_001E': 1100984.0, 'state': '37', 'county': '119'}]\n",
      "Raw Census API response: [{'B18101_001E': 1095629.0, 'B27001_028E': 17571.0, 'B01001_001E': 1100984.0, 'C24050_026E': 13110.0, 'state': '37', 'county': '119'}]\n",
      "Raw Census API response: [{'NAME': 'Mecklenburg County, North Carolina', 'B19013_001E': 73124.0, 'B25003_002E': 245766.0, 'B23025_005E': 28741.0, 'B01001_001E': 1100984.0, 'state': '37', 'county': '119'}]\n",
      "Raw Census API response: [{'B01001_001E': 1100984.0, 'C24050_001E': 591051.0, 'state': '37', 'county': '119'}]\n",
      "Data saved to impact_tool_output.csv\n",
      "Geocoded to: (35.20854790943231, -80.8311796379137)\n",
      "Completed data collection in 17.97 seconds\n",
      "Graphs saved as PNG files: identity_diversity.png, connectivity_metrics.png, wellness_metrics.png, prosperity_metrics.png, finance_metric.png, overall_scores.png\n"
     ]
    }
   ],
   "source": [
    "import requests  # Imports library for HTTP API calls\n",
    "from geopy.geocoders import Nominatim  # Imports Nominatim for geocoding\n",
    "from geopy.extra.rate_limiter import RateLimiter  # Imports RateLimiter for request throttling\n",
    "import pandas as pd  # Imports pandas for data handling\n",
    "from census import Census  # Imports Census for ACS5 data access\n",
    "import time  # Imports time for timing operations\n",
    "import os  # Imports os for system interactions\n",
    "import matplotlib.pyplot as plt  # Imports matplotlib for visualizations\n",
    "\n",
    "# Constants  # Defines constant values\n",
    "CENSUS_API_KEY = \"86cfe7a999f6607864204747a5ac83b7c77e02fb\"  # Census API key\n",
    "RADIUS = 5  # Radius in miles for OSM queries\n",
    "BASE_YEAR = 2021  # Base year for Census data\n",
    "\n",
    "geolocator = Nominatim(user_agent=\"impact_tool\")  # Initializes Nominatim with user agent\n",
    "geocode = RateLimiter(geolocator.geocode, min_delay_seconds=1, max_retries=3, error_wait_seconds=5)  # Rate-limits geocoding\n",
    "c = Census(CENSUS_API_KEY, year=BASE_YEAR)  # Sets up Census client\n",
    "census_cache = {}  # Empty dict for caching Census data\n",
    "\n",
    "def geocode_address(address):  # Converts address to coordinates\n",
    "    location = geocode(address, timeout=10)  # Geocodes with 10s timeout\n",
    "    if location:  # Checks if geocoding succeeded\n",
    "        return location.latitude, location.longitude  # Returns lat/lon tuple\n",
    "    raise ValueError(\"Address not found\")  # Raises error if failed\n",
    "\n",
    "def get_county_fips(lat, lon):  # Gets FIPS codes from coordinates\n",
    "    url = f\"https://geocoding.geo.census.gov/geocoder/geographies/coordinates?x={lon}&y={lat}&benchmark=Public_AR_Current&vintage=Current_Current&format=json\"  # Builds Census API URL\n",
    "    response = requests.get(url).json()  # Fetches and parses JSON\n",
    "    try:  # Tries to extract FIPS\n",
    "        county = response[\"result\"][\"geographies\"][\"Counties\"][0]  # Gets first county\n",
    "        state_fips = county[\"GEOID\"][:2]  # Extracts state FIPS\n",
    "        county_fips = county[\"GEOID\"][-3:]  # Extracts county FIPS\n",
    "        print(f\"Geocoded to State FIPS: {state_fips}, County FIPS: {county_fips}\")  # Prints FIPS\n",
    "        return state_fips, county_fips  # Returns FIPS tuple\n",
    "    except (KeyError, IndexError):  # Handles missing data\n",
    "        print(\"Error fetching FIPS; defaulting to Mecklenburg, NC\")  # Logs error\n",
    "        return \"37\", \"119\"  # Returns default NC FIPS\n",
    "\n",
    "def fetch_census_data(fields, state_fips=\"37\", county_fips=\"119\"):  # Fetches Census data\n",
    "    cache_key = (county_fips, tuple(fields))  # Creates cache key\n",
    "    if cache_key in census_cache:  # Checks cache\n",
    "        return census_cache[cache_key]  # Returns cached data\n",
    "    try:  # Tries Census library\n",
    "        response = c.acs5.state_county(fields, state_fips, county_fips)  # Queries ACS5\n",
    "        print(f\"Raw Census API response: {response}\")  # Logs response\n",
    "        data = response[0] if response else None  # Extracts first row\n",
    "        census_cache[cache_key] = data  # Caches data\n",
    "        return data  # Returns data\n",
    "    except Exception as e:  # Handles errors\n",
    "        print(f\"Census library error: {e}\")  # Logs error\n",
    "        url = f\"https://api.census.gov/data/{BASE_YEAR}/acs/acs5?get={','.join(fields)}&for=county:{county_fips}&in=state:{state_fips}&key={CENSUS_API_KEY}\"  # Builds direct API URL\n",
    "        response = requests.get(url).json()  # Fetches JSON\n",
    "        print(f\"Direct Census API response: {response}\")  # Logs response\n",
    "        data = dict(zip(response[0], response[1])) if len(response) > 1 else None  # Converts to dict\n",
    "        census_cache[cache_key] = data  # Caches data\n",
    "        return data  # Returns data\n",
    "\n",
    "def scrape_identity(county_fips, state_fips=\"37\"):  # Scrapes diversity data\n",
    "    data = fetch_census_data((\"NAME\", \"B03002_003E\", \"B03002_004E\", \"B03002_012E\", \"B01001_001E\", \"B01002_001E\", \"B05002_013E\"), state_fips=state_fips, county_fips=county_fips)  # Fetches Census data\n",
    "    if not data:  # Checks for no data\n",
    "        return {\"Diversity\": {\"White\": 0, \"Black\": 0, \"Hispanic\": 0, \"Foreign Born\": 0, \"Median Age\": 0}, \"Score\": 0}  # Returns zeros\n",
    "    total_pop = float(data[\"B01001_001E\"])  # Gets total population\n",
    "    diversity = {  # Calculates diversity metrics\n",
    "        \"White\": float(data[\"B03002_003E\"]) / total_pop * 100,  # White percentage\n",
    "        \"Black\": float(data[\"B03002_004E\"]) / total_pop * 100,  # Black percentage\n",
    "        \"Hispanic\": float(data[\"B03002_012E\"]) / total_pop * 100,  # Hispanic percentage\n",
    "        \"Foreign Born\": float(data[\"B05002_013E\"]) / total_pop * 100,  # Foreign-born percentage\n",
    "        \"Median Age\": float(data[\"B01002_001E\"])  # Median age\n",
    "    }\n",
    "    score = min(100, 100 - ((diversity[\"White\"] - 30) / 30 * 50))  # Calculates diversity score\n",
    "    return {\"Diversity\": diversity, \"Score\": score}  # Returns diversity data\n",
    "\n",
    "def scrape_connectivity(lat, lon, state_fips=\"37\"):  # Scrapes connectivity data\n",
    "    try:  # Tries OSM and Census queries\n",
    "        osm_park_url = f\"https://overpass-api.de/api/interpreter?data=[out:json];node(around:{RADIUS*1609.34},{lat},{lon})[leisure=park];out;\"  # Builds OSM park query URL\n",
    "        park_response = requests.get(osm_park_url).json()  # Fetches park data\n",
    "        parks = len(park_response[\"elements\"])  # Counts parks\n",
    "        park_access = min(50, parks * 5)  # Calculates park access score\n",
    "        osm_bus_url = f\"https://overpass-api.de/api/interpreter?data=[out:json];node(around:{RADIUS*1609.34},{lat},{lon})[highway=bus_stop];out;\"  # Builds OSM bus stop query URL\n",
    "        bus_response = requests.get(osm_bus_url).json()  # Fetches bus stop data\n",
    "        bus_stops = len(bus_response[\"elements\"])  # Counts bus stops\n",
    "        state_fips, county_fips = get_county_fips(lat, lon)  # Gets FIPS codes\n",
    "        data = fetch_census_data((\"B08301_010E\", \"B01001_001E\"), state_fips=state_fips, county_fips=county_fips)  # Fetches transit data\n",
    "        transit_pct = float(data[\"B08301_010E\"]) / float(data[\"B01001_001E\"]) * 100 if data else 0  # Calculates transit percentage\n",
    "        score = min(100, (park_access / 50 * 30) + (bus_stops / 100 * 30) + (transit_pct / 2 * 40))  # Calculates connectivity score\n",
    "        return {\"Park Access (%)\": park_access, \"Bus Stops\": bus_stops, \"Transit (%)\": transit_pct, \"Score\": score}  # Returns connectivity data\n",
    "    except Exception as e:  # Handles errors\n",
    "        print(f\"Error in scrape_connectivity: {e}\")  # Logs error\n",
    "        return {\"Park Access (%)\": 0, \"Bus Stops\": 0, \"Transit (%)\": 0, \"Score\": 0}  # Returns zeros\n",
    "\n",
    "def scrape_wellness(county_fips, state_fips=\"37\"):  # Scrapes wellness data\n",
    "    data = fetch_census_data((\"B18101_001E\", \"B27001_028E\", \"B01001_001E\", \"C24050_026E\"), state_fips=state_fips, county_fips=county_fips)  # Fetches Census data\n",
    "    if not data:  # Checks for no data\n",
    "        return {\"Obesity Proxy (%)\": 0, \"Uninsured (%)\": 0, \"Provider Ratio\": 0, \"Score\": 0}  # Returns zeros\n",
    "    total_pop = float(data[\"B01001_001E\"])  # Gets total population\n",
    "    obesity_proxy = float(data[\"B18101_001E\"]) / total_pop * 100  # Calculates disability percentage\n",
    "    uninsured = float(data[\"B27001_028E\"]) / total_pop * 100  # Calculates uninsured percentage\n",
    "    provider_ratio = float(data[\"B01001_001E\"]) / float(data[\"C24050_026E\"]) if float(data[\"C24050_026E\"]) > 0 else 1000  # Calculates provider ratio\n",
    "    score = min(100, 100 - ((obesity_proxy - 30) * 1.5) - ((uninsured - 10) * 3) + ((300 - provider_ratio) / 10))  # Calculates wellness score\n",
    "    return {\"Obesity Proxy (%)\": obesity_proxy, \"Uninsured (%)\": uninsured, \"Provider Ratio\": provider_ratio, \"Score\": score}  # Returns wellness data\n",
    "\n",
    "def scrape_prosperity(county_fips, state_fips=\"37\"):  # Scrapes prosperity data\n",
    "    data = fetch_census_data((\"NAME\", \"B19013_001E\", \"B25003_002E\", \"B23025_005E\", \"B01001_001E\"), state_fips=state_fips, county_fips=county_fips)  # Fetches Census data\n",
    "    if not data:  # Checks for no data\n",
    "        return {\"Median Income ($)\": 0, \"Home Ownership (%)\": 0, \"Unemployment (%)\": 0, \"Score\": 0}  # Returns zeros\n",
    "    total_pop = float(data[\"B01001_001E\"])  # Gets total population\n",
    "    income = float(data[\"B19013_001E\"])  # Gets median income\n",
    "    home_ownership = float(data[\"B25003_002E\"]) / total_pop * 100  # Calculates home ownership percentage\n",
    "    unemployment = float(data[\"B23025_005E\"]) / total_pop * 100  # Calculates unemployment percentage\n",
    "    score = min(100, ((income / 60000) * 50) + ((home_ownership / 65) * 30) - ((unemployment - 4) * 10))  # Calculates prosperity score\n",
    "    return {\"Median Income ($)\": income, \"Home Ownership (%)\": home_ownership, \"Unemployment (%)\": unemployment, \"Score\": score}  # Returns prosperity data\n",
    "\n",
    "def scrape_finance(county_fips, state_fips=\"37\"):  # Scrapes finance data\n",
    "    data = fetch_census_data((\"B01001_001E\", \"C24050_001E\"), state_fips=state_fips, county_fips=county_fips)  # Fetches Census data\n",
    "    if not data:  # Checks for no data\n",
    "        return {\"Grants Proxy (per 1000)\": 0, \"Score\": 0}  # Returns zeros\n",
    "    total_pop = float(data[\"B01001_001E\"])  # Gets total population\n",
    "    biz_activity = float(data[\"C24050_001E\"]) / total_pop * 1000  # Calculates business activity per 1000\n",
    "    grants_proxy = min(10, biz_activity / 50)  # Calculates grants proxy\n",
    "    score = min(100, grants_proxy * 8)  # Calculates finance score\n",
    "    return {\"Grants Proxy (per 1000)\": grants_proxy, \"Score\": score}  # Returns finance data\n",
    "\n",
    "def automate_impact_tool(address):  # Main function to run impact tool\n",
    "    print(f\"Processing {address}...\")  # Logs processing start\n",
    "    lat, lon = geocode_address(address)  # Geocodes address\n",
    "    state_fips, county_fips = get_county_fips(lat, lon)  # Gets FIPS codes\n",
    "    data = {  # Collects data from all scrape functions\n",
    "        \"Identity\": scrape_identity(county_fips, state_fips),  # Gets identity data\n",
    "        \"Connectivity\": scrape_connectivity(lat, lon, state_fips),  # Gets connectivity data\n",
    "        \"Wellness\": scrape_wellness(county_fips, state_fips),  # Gets wellness data\n",
    "        \"Prosperity\": scrape_prosperity(county_fips, state_fips),  # Gets prosperity data\n",
    "        \"Finance\": scrape_finance(county_fips, state_fips)  # Gets finance data\n",
    "    }\n",
    "    flat_data = {}  # Initializes flat data dict\n",
    "    for category, values in data.items():  # Flattens nested data\n",
    "        for key, val in values.items():  # Loops through key-value pairs\n",
    "            flat_data[f\"{category}_{key}\"] = val  # Creates flat key-value pairs\n",
    "    df = pd.DataFrame([flat_data])  # Creates DataFrame from flat data\n",
    "    df.to_csv(\"impact_tool_output.csv\", index=False)  # Saves to CSV\n",
    "    print(\"Data saved to impact_tool_output.csv\")  # Logs CSV save\n",
    "    print(f\"Geocoded to: ({lat}, {lon})\")  # Logs coordinates\n",
    "    return df  # Returns DataFrame\n",
    "\n",
    "def visualize_data(df):  # Visualizes data as graphs\n",
    "    plt.figure(figsize=(8, 6))  # Sets figure size for pie chart\n",
    "    diversity = df[\"Identity_Diversity\"].iloc[0]  # Gets diversity data\n",
    "    plt.pie([diversity[\"White\"], diversity[\"Black\"], diversity[\"Hispanic\"], diversity[\"Foreign Born\"]], labels=[\"White\", \"Black\", \"Hispanic\", \"Foreign Born\"], autopct='%1.1f%%', startangle=90, colors=['#FF9999', '#66B2FF', '#99FF99', '#FFCC99'])  # Plots pie chart\n",
    "    plt.title(\"Community Diversity\", fontsize=14)  # Sets title\n",
    "    plt.axis('equal')  # Ensures circular pie\n",
    "    plt.savefig(\"identity_diversity.png\")  # Saves pie chart\n",
    "    plt.close()  # Closes figure\n",
    "\n",
    "    plt.figure(figsize=(10, 6))  # Sets figure size for bar chart\n",
    "    connectivity_metrics = [\"Park Access (%)\", \"Bus Stops\", \"Transit (%)\"]  # Defines connectivity metrics\n",
    "    connectivity_values = [df[\"Connectivity_Park Access (%)\"].iloc[0], df[\"Connectivity_Bus Stops\"].iloc[0] / 10, df[\"Connectivity_Transit (%)\"].iloc[0] * 10]  # Scales values\n",
    "    plt.bar(connectivity_metrics, connectivity_values, color=['#FFCC00', '#00CC66', '#0066CC'])  # Plots bar chart\n",
    "    plt.title(\"Connectivity Overview\", fontsize=14)  # Sets title\n",
    "    plt.ylabel(\"Value (Scaled)\", fontsize=12)  # Sets y-axis label\n",
    "    for i, v in enumerate(connectivity_values):  # Adds value labels\n",
    "        plt.text(i, v + 1, f\"{[df['Connectivity_Park Access (%)'].iloc[0], df['Connectivity_Bus Stops'].iloc[0], df['Connectivity_Transit (%)'].iloc[0]][i]}\", ha='center')  # Labels bars\n",
    "    plt.savefig(\"connectivity_metrics.png\")  # Saves bar chart\n",
    "    plt.close()  # Closes figure\n",
    "\n",
    "    plt.figure(figsize=(10, 6))  # Sets figure size for wellness\n",
    "    wellness_metrics = [\"Obesity Proxy (%)\", \"Uninsured (%)\", \"Provider Ratio\"]  # Defines wellness metrics\n",
    "    wellness_values = [df[\"Wellness_Obesity Proxy (%)\"].iloc[0], df[\"Wellness_Uninsured (%)\"].iloc[0] * 10, df[\"Wellness_Provider Ratio\"].iloc[0] / 5]  # Scales values\n",
    "    plt.bar(wellness_metrics, wellness_values, color=['#CC33FF', '#FF33CC', '#33CCCC'])  # Plots bar chart\n",
    "    plt.title(\"Wellness Overview\", fontsize=14)  # Sets title\n",
    "    plt.ylabel(\"Value (Scaled)\", fontsize=12)  # Sets y-axis label\n",
    "    for i, v in enumerate(wellness_values):  # Adds value labels\n",
    "        plt.text(i, v + 1, f\"{[df['Wellness_Obesity Proxy (%)'].iloc[0], df['Wellness_Uninsured (%)'].iloc[0], df['Wellness_Provider Ratio'].iloc[0]][i]:.1f}\", ha='center')  # Labels bars\n",
    "    plt.savefig(\"wellness_metrics.png\")  # Saves bar chart\n",
    "    plt.close()  # Closes figure\n",
    "\n",
    "    plt.figure(figsize=(10, 6))  # Sets figure size for prosperity\n",
    "    prosperity_metrics = [\"Median Income ($K)\", \"Home Ownership (%)\", \"Unemployment (%)\"]  # Defines prosperity metrics\n",
    "    prosperity_values = [df[\"Prosperity_Median Income ($)\"].iloc[0] / 1000, df[\"Prosperity_Home Ownership (%)\"].iloc[0], df[\"Prosperity_Unemployment (%)\"].iloc[0] * 10]  # Scales values\n",
    "    plt.bar(prosperity_metrics, prosperity_values, color=['#FF9900', '#0099FF', '#CC0000'])  # Plots bar chart\n",
    "    plt.title(\"Prosperity Overview\", fontsize=14)  # Sets title\n",
    "    plt.ylabel(\"Value (Scaled)\", fontsize=12)  # Sets y-axis label\n",
    "    for i, v in enumerate(prosperity_values):  # Adds value labels\n",
    "        plt.text(i, v + 1, f\"{[df['Prosperity_Median Income ($)'].iloc[0]/1000, df['Prosperity_Home Ownership (%)'].iloc[0], df['Prosperity_Unemployment (%)'].iloc[0]][i]:.1f}\", ha='center')  # Labels bars\n",
    "    plt.savefig(\"prosperity_metrics.png\")  # Saves bar chart\n",
    "    plt.close()  # Closes figure\n",
    "\n",
    "    plt.figure(figsize=(6, 6))  # Sets figure size for finance\n",
    "    plt.bar([\"Grants Proxy (per 1000)\"], [df[\"Finance_Grants Proxy (per 1000)\"].iloc[0]], color='#00CC99')  # Plots finance bar\n",
    "    plt.title(\"Finance Overview\", fontsize=14)  # Sets title\n",
    "    plt.ylabel(\"Grants per 1000\", fontsize=12)  # Sets y-axis label\n",
    "    plt.text(0, df[\"Finance_Grants Proxy (per 1000)\"].iloc[0] + 0.5, f\"{df['Finance_Grants Proxy (per 1000)'].iloc[0]}\", ha='center')  # Adds value label\n",
    "    plt.savefig(\"finance_metric.png\")  # Saves bar chart\n",
    "    plt.close()  # Closes figure\n",
    "\n",
    "    plt.figure(figsize=(12, 6))  # Sets figure size for scores\n",
    "    categories = [\"Identity\", \"Connectivity\", \"Wellness\", \"Prosperity\", \"Finance\"]  # Defines score categories\n",
    "    scores = [df[\"Identity_Score\"].iloc[0], df[\"Connectivity_Score\"].iloc[0], df[\"Wellness_Score\"].iloc[0], df[\"Prosperity_Score\"].iloc[0], df[\"Finance_Score\"].iloc[0]]  # Gets scores\n",
    "    plt.bar(categories, scores, color=['#FF9999', '#66B2FF', '#CC33FF', '#FF9900', '#00CC99'])  # Plots bar chart\n",
    "    plt.title(\"Overall Impact Scores\", fontsize=14)  # Sets title\n",
    "    plt.ylabel(\"Score (0-100)\", fontsize=12)  # Sets y-axis label\n",
    "    plt.ylim(0, 100)  # Sets y-axis range\n",
    "    for i, v in enumerate(scores):  # Adds score labels\n",
    "        plt.text(i, v + 2, f\"{v:.1f}\", ha='center')  # Labels bars\n",
    "    plt.savefig(\"overall_scores.png\")  # Saves bar chart\n",
    "    plt.close()  # Closes figure\n",
    "    print(\"Graphs saved as PNG files: identity_diversity.png, connectivity_metrics.png, wellness_metrics.png, prosperity_metrics.png, finance_metric.png, overall_scores.png\")  # Logs saved files\n",
    "\n",
    "if __name__ == \"__main__\":  # Runs if script is main\n",
    "    address = input()  # Takes user input for address\n",
    "    start_time = time.time()  # Starts timer\n",
    "    result = automate_impact_tool(address)  # Runs impact tool\n",
    "    print(f\"Completed data collection in {time.time() - start_time:.2f} seconds\")  # Logs execution time\n",
    "    visualize_data(result)  # Generates visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69f49540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter address: 123 Main St, Charlotte, NC\n",
      "Processing 123 Main St, Charlotte, NC...\n",
      "Geocoded 123 Main St, Charlotte, NC to (35.20854790943231, -80.8311796379137)\n",
      "Geocoding API response: {'result': {'geographies': {'States': [{'STATENS': '01027616', 'GEOID': '37', 'CENTLAT': '+35.5401756', 'AREAWATER': '13454822676', 'STATE': '37', 'BASENAME': 'North Carolina', 'STUSAB': 'NC', 'OID': '2749018629826', 'LSADC': '00', 'FUNCSTAT': 'A', 'INTPTLAT': '+35.5397100', 'DIVISION': '5', 'NAME': 'North Carolina', 'REGION': '3', 'OBJECTID': 9, 'CENTLON': '-079.1299320', 'AREALAND': '125934598156', 'INTPTLON': '-079.1308636', 'MTFCC': 'G4000'}], 'Combined Statistical Areas': [{'POP100': '', 'GEOID': '172', 'CENTLAT': '+35.3339069', 'AREAWATER': '426777631', 'BASENAME': 'Charlotte-Concord, NC-SC', 'OID': '2619034687907997', 'LSADC': 'M0', 'FUNCSTAT': 'S', 'INTPTLAT': '+35.3344011', 'NAME': 'Charlotte-Concord, NC-SC CSA', 'OBJECTID': 177, 'CSA': '172', 'CENTLON': '-081.0004691', 'INTPTLON': '-081.0053042', 'AREALAND': '22108319371', 'HU100': '', 'MTFCC': 'G3100'}], 'County Subdivisions': [{'COUSUB': '93268', 'GEOID': '3711993268', 'CENTLAT': '+35.2086284', 'AREAWATER': '5132944', 'STATE': '37', 'BASENAME': '1, Charlotte', 'OID': '27690422693014', 'LSADC': '45', 'FUNCSTAT': 'N', 'INTPTLAT': '+35.2090447', 'NAME': 'Township 1, Charlotte', 'OBJECTID': 35910, 'CENTLON': '-080.8308159', 'COUSUBCC': 'Z1', 'AREALAND': '807058441', 'INTPTLON': '-080.8309902', 'MTFCC': 'G4040', 'COUSUBNS': '01026930', 'COUNTY': '119'}], 'Urban Areas': [{'GEOID': '15670', 'CENTLAT': '+35.2266885', 'AREAWATER': '26675983', 'BASENAME': 'Charlotte, NC--SC', 'OID': '27021305287887', 'UA': '15670', 'LSADC': '67', 'FUNCSTAT': 'S', 'INTPTLAT': '+35.2275363', 'NAME': 'Charlotte, NC--SC Urban Area', 'OBJECTID': 117, 'CENTLON': '-080.8070138', 'AREALAND': '1703213744', 'INTPTLON': '-080.8065590', 'MTFCC': 'G3500'}], 'Incorporated Places': [{'DISP_CLR': 2, 'NECTAPCI': 'N', 'GEOID': '3712000', 'CENTLAT': '+35.2086284', 'AREAWATER': '5132944', 'BASENAME': 'Charlotte', 'STATE': '37', 'OID': '27890422717479', 'LSADC': '25', 'PLACE': '12000', 'FUNCSTAT': 'A', 'INTPTLAT': '+35.2090447', 'NAME': 'Charlotte city', 'OBJECTID': 32377, 'PLACECC': 'C1', 'CENTLON': '-080.8308159', 'CBSAPCI': 'Y', 'AREALAND': '807058441', 'INTPTLON': '-080.8309902', 'PLACENS': '02404032', 'MTFCC': 'G4110'}], 'Counties': [{'GEOID': '37119', 'CENTLAT': '+35.2466354', 'AREAWATER': '58184181', 'STATE': '37', 'BASENAME': 'Mecklenburg', 'OID': '27590422669341', 'LSADC': '06', 'FUNCSTAT': 'A', 'INTPTLAT': '+35.2468623', 'NAME': 'Mecklenburg County', 'OBJECTID': 1433, 'CENTLON': '-080.8327111', 'COUNTYCC': 'H1', 'COUNTYNS': '01008570', 'AREALAND': '1356155383', 'INTPTLON': '-080.8338317', 'MTFCC': 'G4020', 'COUNTY': '119'}], '2024 State Legislative Districts - Upper': [{'GEOID': '37041', 'CENTLAT': '+35.2583965', 'AREAWATER': '2073996', 'STATE': '37', 'BASENAME': '41', 'OID': '2129035952746744', 'SLDU': '041', 'LSADC': 'LU', 'FUNCSTAT': 'N', 'INTPTLAT': '+35.2579045', 'NAME': 'State Senate District 41', 'OBJECTID': 684, 'CENTLON': '-080.8836165', 'LSY': '2024', 'AREALAND': '227678923', 'INTPTLON': '-080.8816048', 'MTFCC': 'G5210', 'LDTYP': 'O'}], '2024 State Legislative Districts - Lower': [{'GEOID': '37102', 'CENTLAT': '+35.2248334', 'SLDL': '102', 'AREAWATER': '39039', 'STATE': '37', 'BASENAME': '102', 'OID': '2139035952746981', 'LSADC': 'LL', 'FUNCSTAT': 'N', 'INTPTLAT': '+35.2231598', 'NAME': 'State House District 102', 'OBJECTID': 2051, 'CENTLON': '-080.8088962', 'LSY': '2024', 'AREALAND': '53277420', 'INTPTLON': '-080.8093517', 'MTFCC': 'G5220', 'LDTYP': 'O'}], '2020 Census Blocks': [{'SUFFIX': '', 'GEOID': '371190026001018', 'CENTLAT': '+35.2090447', 'BLOCK': '1018', 'AREAWATER': '0', 'STATE': '37', 'BASENAME': '1018', 'OID': '210701007248373', 'LSADC': 'BK', 'FUNCSTAT': 'S', 'INTPTLAT': '+35.2090447', 'NAME': 'Block 1018', 'OBJECTID': 608386, 'TRACT': '002600', 'CENTLON': '-080.8309902', 'BLKGRP': '1', 'AREALAND': '21244', 'INTPTLON': '-080.8309902', 'MTFCC': 'G5040', 'LWBLKTYP': 'L', 'UR': 'U', 'COUNTY': '119'}], 'Census Tracts': [{'GEOID': '37119002600', 'CENTLAT': '+35.2100741', 'AREAWATER': '0', 'STATE': '37', 'BASENAME': '26', 'OID': '20790422821339', 'LSADC': 'CT', 'FUNCSTAT': 'S', 'INTPTLAT': '+35.2100741', 'NAME': 'Census Tract 26', 'OBJECTID': 24271, 'TRACT': '002600', 'CENTLON': '-080.8316138', 'AREALAND': '704621', 'INTPTLON': '-080.8316138', 'MTFCC': 'G5020', 'COUNTY': '119'}], '119th Congressional Districts': [{'GEOID': '3712', 'CENTLAT': '+35.2388409', 'CDSESSN': '119', 'AREAWATER': '3995126', 'BASENAME': '12', 'STATE': '37', 'OID': '2119035952747010', 'LSADC': 'C2', 'FUNCSTAT': 'N', 'INTPTLAT': '+35.2393588', 'NAME': 'Congressional District 12', 'OBJECTID': 88, 'CENTLON': '-080.8143037', 'CD119': '12', 'AREALAND': '707970784', 'INTPTLON': '-080.8143733', 'MTFCC': 'G5200'}]}, 'input': {'vintage': {'isDefault': True, 'id': '4', 'vintageName': 'Current_Current', 'vintageDescription': 'Current Vintage - Current Benchmark'}, 'location': {'x': -80.8311796379137, 'y': 35.20854790943231}, 'benchmark': {'isDefault': True, 'benchmarkDescription': 'Public Address Ranges - Current Benchmark', 'id': '4', 'benchmarkName': 'Public_AR_Current'}}}}\n",
      "Geocoded to State FIPS: 37, County FIPS: 119\n",
      "ACS5 API call successful for fields: ('NAME', 'B03002_003E', 'B03002_004E', 'B03002_012E', 'B01001_001E', 'B01002_001E', 'B05002_013E')\n",
      "Raw Census API response: [{'NAME': 'Mecklenburg County, North Carolina', 'B03002_003E': 501903.0, 'B03002_004E': 341395.0, 'B03002_012E': 150566.0, 'B01001_001E': 1100984.0, 'B01002_001E': 35.4, 'B05002_013E': 175619.0, 'state': '37', 'county': '119'}]\n",
      "Parks: 3, Bus Stops: 198\n",
      "Error in scrape_connectivity: Failed to fetch FIPS codes for coordinates (35.20854790943231, -80.8311796379137): HTTPSConnectionPool(host='geocoding.geo.census.gov', port=443): Read timed out. (read timeout=10)\n",
      "ACS5 API call successful for fields: ('B18101_001E', 'B27001_028E', 'B01001_001E', 'C24050_026E')\n",
      "Raw Census API response: [{'B18101_001E': 1095629.0, 'B27001_028E': 17571.0, 'B01001_001E': 1100984.0, 'C24050_026E': 13110.0, 'state': '37', 'county': '119'}]\n",
      "ACS5 API call successful for fields: ('NAME', 'B19013_001E', 'B25003_002E', 'B23025_005E', 'B01001_001E')\n",
      "Raw Census API response: [{'NAME': 'Mecklenburg County, North Carolina', 'B19013_001E': 73124.0, 'B25003_002E': 245766.0, 'B23025_005E': 28741.0, 'B01001_001E': 1100984.0, 'state': '37', 'county': '119'}]\n",
      "ACS5 API call successful for fields: ('B01001_001E', 'C24050_001E')\n",
      "Raw Census API response: [{'B01001_001E': 1100984.0, 'C24050_001E': 591051.0, 'state': '37', 'county': '119'}]\n",
      "Scores: {'Identity': 74.0220566329756, 'Connectivity': 0, 'Wellness': 42.54371934570058, 'Prosperity': 85.13448076191796, 'Finance': 80}\n",
      "Data saved to impact_tool_output.csv\n",
      "Geocoded to: (35.20854790943231, -80.8311796379137)\n",
      "Completed data collection in 32.93 seconds\n",
      "Graphs saved as PNG files: identity_diversity.png, connectivity_metrics.png, wellness_metrics.png, prosperity_metrics.png, finance_metric.png, overall_scores.png\n"
     ]
    }
   ],
   "source": [
    "#123 Main St, Charlotte, NC\n",
    "import requests  # Imports library for HTTP API calls\n",
    "from geopy.geocoders import Nominatim  # Imports Nominatim for geocoding\n",
    "from geopy.extra.rate_limiter import RateLimiter  # Imports RateLimiter for request throttling\n",
    "import pandas as pd  # Imports pandas for data handling\n",
    "from census import Census  # Imports Census for ACS5 data access\n",
    "import time  # Imports time for timing operations\n",
    "import os  # Imports os for system interactions\n",
    "import matplotlib.pyplot as plt  # Imports matplotlib for visualizations\n",
    "\n",
    "# Constants  # Defines constant values\n",
    "CENSUS_API_KEY = \"86cfe7a999f6607864204747a5ac83b7c77e02fb\"  # Census API key\n",
    "RADIUS = 5  # Radius in miles for OSM queries\n",
    "BASE_YEAR = 2021  # Base year for Census data\n",
    "\n",
    "geolocator = Nominatim(user_agent=\"impact_tool\")  # Initializes Nominatim with user agent\n",
    "geocode = RateLimiter(geolocator.geocode, min_delay_seconds=1, max_retries=3, error_wait_seconds=5)  # Rate-limits geocoding\n",
    "c = Census(CENSUS_API_KEY, year=BASE_YEAR)  # Sets up Census client\n",
    "census_cache = {}  # Empty dict for caching Census data\n",
    "\n",
    "def geocode_address(address):  # Converts address to coordinates\n",
    "    location = geocode(address, timeout=10)  # Geocodes with 10s timeout\n",
    "    if location:  # Checks if geocoding succeeded\n",
    "        print(f\"Geocoded {address} to ({location.latitude}, {location.longitude})\")\n",
    "        return location.latitude, location.longitude  # Returns lat/lon tuple\n",
    "    raise ValueError(f\"Address not found: {address}\")  # Raises error if failed\n",
    "\n",
    "def get_county_fips(lat, lon):  # Gets FIPS codes from coordinates\n",
    "    url = f\"https://geocoding.geo.census.gov/geocoder/geographies/coordinates?x={lon}&y={lat}&benchmark=Public_AR_Current&vintage=Current_Current&format=json\"  # Builds Census API URL\n",
    "    try:\n",
    "        response = requests.get(url, timeout=10)  # Fetches with timeout\n",
    "        response.raise_for_status()  # Raises for bad HTTP status\n",
    "        data = response.json()\n",
    "        print(f\"Geocoding API response: {data}\")  # Logs response\n",
    "        county = data[\"result\"][\"geographies\"][\"Counties\"][0]  # Gets first county\n",
    "        state_fips = county[\"GEOID\"][:2]  # Extracts state FIPS\n",
    "        county_fips = county[\"GEOID\"][-3:]  # Extracts county FIPS\n",
    "        print(f\"Geocoded to State FIPS: {state_fips}, County FIPS: {county_fips}\")\n",
    "        return state_fips, county_fips  # Returns FIPS tuple\n",
    "    except (requests.RequestException, KeyError, IndexError) as e:\n",
    "        raise ValueError(f\"Failed to fetch FIPS codes for coordinates ({lat}, {lon}): {str(e)}\")  # Raises error on failure\n",
    "\n",
    "def fetch_census_data(fields, state_fips=\"37\", county_fips=\"119\"):  # Fetches Census data\n",
    "    cache_key = (county_fips, tuple(fields))  # Creates cache key\n",
    "    if cache_key in census_cache:  # Checks cache\n",
    "        print(f\"Using cached data for {fields}\")\n",
    "        return census_cache[cache_key]  # Returns cached data\n",
    "    try:  # Tries Census library\n",
    "        response = c.acs5.state_county(fields, state_fips, county_fips)  # Queries ACS5\n",
    "        print(f\"ACS5 API call successful for fields: {fields}\")\n",
    "        print(f\"Raw Census API response: {response}\")\n",
    "        data = response[0] if response else None  # Extracts first row\n",
    "        census_cache[cache_key] = data  # Caches data\n",
    "        return data  # Returns data\n",
    "    except Exception as e:  # Handles errors\n",
    "        print(f\"Census library error: {e}\")\n",
    "        url = f\"https://api.census.gov/data/{BASE_YEAR}/acs/acs5?get={','.join(fields)}&for=county:{county_fips}&in=state:{state_fips}&key={CENSUS_API_KEY}\"  # Builds direct API URL\n",
    "        try:\n",
    "            response = requests.get(url, timeout=10)\n",
    "            response.raise_for_status()\n",
    "            print(f\"Direct ACS5 API call successful: {url}\")\n",
    "            data = response.json()\n",
    "            print(f\"Direct Census API response: {data}\")\n",
    "            data = dict(zip(data[0], data[1])) if len(data) > 1 else None\n",
    "            census_cache[cache_key] = data\n",
    "            return data\n",
    "        except requests.RequestException as e:\n",
    "            raise ValueError(f\"Failed to fetch Census data for fields {fields}: {str(e)}\")  # Raises error\n",
    "\n",
    "def scrape_identity(county_fips, state_fips):  # Scrapes diversity data\n",
    "    data = fetch_census_data((\"NAME\", \"B03002_003E\", \"B03002_004E\", \"B03002_012E\", \"B01001_001E\", \"B01002_001E\", \"B05002_013E\"), state_fips=state_fips, county_fips=county_fips)  # Fetches Census data\n",
    "    if not data:  # Checks for no data\n",
    "        return {\"Diversity\": {\"White\": 0, \"Black\": 0, \"Hispanic\": 0, \"Foreign Born\": 0, \"Median Age\": 0}, \"Score\": 0}  # Returns zeros\n",
    "    total_pop = float(data[\"B01001_001E\"])  # Gets total population\n",
    "    diversity = {  # Calculates diversity metrics\n",
    "        \"White\": float(data[\"B03002_003E\"]) / total_pop * 100,  # White percentage\n",
    "        \"Black\": float(data[\"B03002_004E\"]) / total_pop * 100,  # Black percentage\n",
    "        \"Hispanic\": float(data[\"B03002_012E\"]) / total_pop * 100,  # Hispanic percentage\n",
    "        \"Foreign Born\": float(data[\"B05002_013E\"]) / total_pop * 100,  # Foreign-born percentage\n",
    "        \"Median Age\": float(data[\"B01002_001E\"])  # Median age\n",
    "    }\n",
    "    score = min(100, 100 - ((diversity[\"White\"] - 30) / 30 * 50))  # Calculates diversity score\n",
    "    return {\"Diversity\": diversity, \"Score\": score}  # Returns diversity data\n",
    "\n",
    "def scrape_connectivity(lat, lon, state_fips):  # Scrapes connectivity data\n",
    "    try:  # Tries OSM and Census queries\n",
    "        osm_park_url = f\"https://overpass-api.de/api/interpreter?data=[out:json];node(around:{RADIUS*1609.34},{lat},{lon})[leisure=park];out;\"  # Builds OSM park query URL\n",
    "        park_response = requests.get(osm_park_url).json()  # Fetches park data\n",
    "        parks = len(park_response[\"elements\"])  # Counts parks\n",
    "        park_access = min(50, parks * 5)  # Calculates park access score\n",
    "        osm_bus_url = f\"https://overpass-api.de/api/interpreter?data=[out:json];node(around:{RADIUS*1609.34},{lat},{lon})[highway=bus_stop];out;\"  # Builds OSM bus stop query URL\n",
    "        bus_response = requests.get(osm_bus_url).json()  # Fetches bus stop data\n",
    "        bus_stops = len(bus_response[\"elements\"])  # Counts bus stops\n",
    "        print(f\"Parks: {parks}, Bus Stops: {bus_stops}\")  # Logs OSM counts\n",
    "        state_fips, county_fips = get_county_fips(lat, lon)  # Gets FIPS codes\n",
    "        data = fetch_census_data((\"B08301_010E\", \"B01001_001E\"), state_fips=state_fips, county_fips=county_fips)  # Fetches transit data\n",
    "        transit_pct = float(data[\"B08301_010E\"]) / float(data[\"B01001_001E\"]) * 100 if data else 0  # Calculates transit percentage\n",
    "        score = min(100, (park_access / 50 * 30) + min(15, bus_stops / 200 * 30) + (transit_pct / 2 * 40))  # Adjusted connectivity score\n",
    "        return {\"Park Access (%)\": park_access, \"Bus Stops\": bus_stops, \"Transit (%)\": transit_pct, \"Score\": score}  # Returns connectivity data\n",
    "    except Exception as e:  # Handles errors\n",
    "        print(f\"Error in scrape_connectivity: {e}\")  # Logs error\n",
    "        return {\"Park Access (%)\": 0, \"Bus Stops\": 0, \"Transit (%)\": 0, \"Score\": 0}  # Returns zeros\n",
    "\n",
    "def scrape_wellness(county_fips, state_fips):  # Scrapes wellness data\n",
    "    data = fetch_census_data((\"B18101_001E\", \"B27001_028E\", \"B01001_001E\", \"C24050_026E\"), state_fips=state_fips, county_fips=county_fips)  # Fetches Census data\n",
    "    if not data:  # Checks for no data\n",
    "        return {\"Obesity Proxy (%)\": 0, \"Uninsured (%)\": 0, \"Provider Ratio\": 0, \"Score\": 0}  # Returns zeros\n",
    "    total_pop = float(data[\"B01001_001E\"])  # Gets total population\n",
    "    obesity_proxy = float(data[\"B18101_001E\"]) / total_pop * 100  # Calculates disability percentage\n",
    "    uninsured = float(data[\"B27001_028E\"]) / total_pop * 100  # Calculates uninsured percentage\n",
    "    provider_ratio = float(data[\"B01001_001E\"]) / float(data[\"C24050_026E\"]) if float(data[\"C24050_026E\"]) > 0 else 1000  # Calculates provider ratio\n",
    "    score = max(0, min(100, 100 - ((obesity_proxy - 30) * 1.5) - ((uninsured - 10) * 3) + ((300 - provider_ratio) / 10)))  # Capped wellness score\n",
    "    return {\"Obesity Proxy (%)\": obesity_proxy, \"Uninsured (%)\": uninsured, \"Provider Ratio\": provider_ratio, \"Score\": score}  # Returns wellness data\n",
    "\n",
    "def scrape_prosperity(county_fips, state_fips):  # Scrapes prosperity data\n",
    "    data = fetch_census_data((\"NAME\", \"B19013_001E\", \"B25003_002E\", \"B23025_005E\", \"B01001_001E\"), state_fips=state_fips, county_fips=county_fips)  # Fetches Census data\n",
    "    if not data:  # Checks for no data\n",
    "        return {\"Median Income ($)\": 0, \"Home Ownership (%)\": 0, \"Unemployment (%)\": 0, \"Score\": 0}  # Returns zeros\n",
    "    total_pop = float(data[\"B01001_001E\"])  # Gets total population\n",
    "    income = float(data[\"B19013_001E\"])  # Gets median income\n",
    "    home_ownership = float(data[\"B25003_002E\"]) / total_pop * 100  # Calculates home ownership percentage\n",
    "    unemployment = float(data[\"B23025_005E\"]) / total_pop * 100  # Calculates unemployment percentage\n",
    "    score = min(100, ((income / 60000) * 50) + ((home_ownership / 65) * 30) - ((unemployment - 4) * 10))  # Calculates prosperity score\n",
    "    return {\"Median Income ($)\": income, \"Home Ownership (%)\": home_ownership, \"Unemployment (%)\": unemployment, \"Score\": score}  # Returns prosperity data\n",
    "\n",
    "def scrape_finance(county_fips, state_fips):  # Scrapes finance data\n",
    "    data = fetch_census_data((\"B01001_001E\", \"C24050_001E\"), state_fips=state_fips, county_fips=county_fips)  # Fetches Census data\n",
    "    if not data:  # Checks for no data\n",
    "        return {\"Grants Proxy (per 1000)\": 0, \"Score\": 0}  # Returns zeros\n",
    "    total_pop = float(data[\"B01001_001E\"])  # Gets total population\n",
    "    biz_activity = float(data[\"C24050_001E\"]) / total_pop * 1000  # Calculates business activity per 1000\n",
    "    grants_proxy = min(10, biz_activity / 50)  # Calculates grants proxy\n",
    "    score = min(100, grants_proxy * 8)  # Calculates finance score\n",
    "    return {\"Grants Proxy (per 1000)\": grants_proxy, \"Score\": score}  # Returns finance data\n",
    "\n",
    "def automate_impact_tool(address):  # Main function to run impact tool\n",
    "    print(f\"Processing {address}...\")  # Logs processing start\n",
    "    try:\n",
    "        lat, lon = geocode_address(address)  # Geocodes address\n",
    "        state_fips, county_fips = get_county_fips(lat, lon)  # Gets FIPS codes\n",
    "        data = {  # Collects data from all scrape functions\n",
    "            \"Identity\": scrape_identity(county_fips, state_fips),  # Gets identity data\n",
    "            \"Connectivity\": scrape_connectivity(lat, lon, state_fips),  # Gets connectivity data\n",
    "            \"Wellness\": scrape_wellness(county_fips, state_fips),  # Gets wellness data\n",
    "            \"Prosperity\": scrape_prosperity(county_fips, state_fips),  # Gets prosperity data\n",
    "            \"Finance\": scrape_finance(county_fips, state_fips)  # Gets finance data\n",
    "        }\n",
    "        flat_data = {}  # Initializes flat data dict\n",
    "        for category, values in data.items():  # Flattens nested data\n",
    "            for key, val in values.items():  # Loops through key-value pairs\n",
    "                flat_data[f\"{category}_{key}\"] = val  # Creates flat key-value pairs\n",
    "        df = pd.DataFrame([flat_data])  # Creates DataFrame from flat data\n",
    "        print(\"Scores:\", {k: v[\"Score\"] for k, v in data.items()})  # Logs scores\n",
    "        df.to_csv(\"impact_tool_output.csv\", index=False)  # Saves to CSV\n",
    "        print(\"Data saved to impact_tool_output.csv\")  # Logs CSV save\n",
    "        print(f\"Geocoded to: ({lat}, {lon})\")  # Logs coordinates\n",
    "        return df  # Returns DataFrame\n",
    "    except ValueError as e:\n",
    "        print(f\"Error processing request: {e}\")\n",
    "        raise  # Re-raises to stop execution\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error: {e}\")\n",
    "        raise  # Re-raises to stop execution\n",
    "\n",
    "def visualize_data(df):  # Visualizes data as graphs\n",
    "    plt.figure(figsize=(8, 6))  # Sets figure size for pie chart\n",
    "    diversity = df[\"Identity_Diversity\"].iloc[0]  # Gets diversity data\n",
    "    plt.pie([diversity[\"White\"], diversity[\"Black\"], diversity[\"Hispanic\"], diversity[\"Foreign Born\"]], labels=[\"White\", \"Black\", \"Hispanic\", \"Foreign Born\"], autopct='%1.1f%%', startangle=90, colors=['#FF9999', '#66B2FF', '#99FF99', '#FFCC99'])  # Plots pie chart\n",
    "    plt.title(\"Community Diversity\", fontsize=14)  # Sets title\n",
    "    plt.axis('equal')  # Ensures circular pie\n",
    "    plt.savefig(\"identity_diversity.png\")  # Saves pie chart\n",
    "    plt.close()  # Closes figure\n",
    "\n",
    "    plt.figure(figsize=(10, 6))  # Sets figure size for bar chart\n",
    "    connectivity_metrics = [\"Park Access (%)\", \"Bus Stops\", \"Transit (%)\"]  # Defines connectivity metrics\n",
    "    connectivity_values = [df[\"Connectivity_Park Access (%)\"].iloc[0], df[\"Connectivity_Bus Stops\"].iloc[0] / 10, df[\"Connectivity_Transit (%)\"].iloc[0] * 10]  # Scales values\n",
    "    plt.bar(connectivity_metrics, connectivity_values, color=['#FFCC00', '#00CC66', '#0066CC'])  # Plots bar chart\n",
    "    plt.title(\"Connectivity Overview\", fontsize=14)  # Sets title\n",
    "    plt.ylabel(\"Value (Scaled)\", fontsize=12)  # Sets y-axis label\n",
    "    for i, v in enumerate(connectivity_values):  # Adds value labels\n",
    "        plt.text(i, v + 1, f\"{[df['Connectivity_Park Access (%)'].iloc[0], df['Connectivity_Bus Stops'].iloc[0], df['Connectivity_Transit (%)'].iloc[0]][i]}\", ha='center')  # Labels bars\n",
    "    plt.savefig(\"connectivity_metrics.png\")  # Saves bar chart\n",
    "    plt.close()  # Closes figure\n",
    "\n",
    "    plt.figure(figsize=(10, 6))  # Sets figure size for wellness\n",
    "    wellness_metrics = [\"Obesity Proxy (%)\", \"Uninsured (%)\", \"Provider Ratio\"]  # Defines wellness metrics\n",
    "    wellness_values = [df[\"Wellness_Obesity Proxy (%)\"].iloc[0], df[\"Wellness_Uninsured (%)\"].iloc[0] * 10, df[\"Wellness_Provider Ratio\"].iloc[0] / 5]  # Scales values\n",
    "    plt.bar(wellness_metrics, wellness_values, color=['#CC33FF', '#FF33CC', '#33CCCC'])  # Plots bar chart\n",
    "    plt.title(\"Wellness Overview\", fontsize=14)  # Sets title\n",
    "    plt.ylabel(\"Value (Scaled)\", fontsize=12)  # Sets y-axis label\n",
    "    for i, v in enumerate(wellness_values):  # Adds value labels\n",
    "        plt.text(i, v + 1, f\"{[df['Wellness_Obesity Proxy (%)'].iloc[0], df['Wellness_Uninsured (%)'].iloc[0], df['Wellness_Provider Ratio'].iloc[0]][i]:.1f}\", ha='center')  # Labels bars\n",
    "    plt.savefig(\"wellness_metrics.png\")  # Saves bar chart\n",
    "    plt.close()  # Closes figure\n",
    "\n",
    "    plt.figure(figsize=(10, 6))  # Sets figure size for prosperity\n",
    "    prosperity_metrics = [\"Median Income ($K)\", \"Home Ownership (%)\", \"Unemployment (%)\"]  # Defines prosperity metrics\n",
    "    prosperity_values = [df[\"Prosperity_Median Income ($)\"].iloc[0] / 1000, df[\"Prosperity_Home Ownership (%)\"].iloc[0], df[\"Prosperity_Unemployment (%)\"].iloc[0] * 10]  # Scales values\n",
    "    plt.bar(prosperity_metrics, prosperity_values, color=['#FF9900', '#0099FF', '#CC0000'])  # Plots bar chart\n",
    "    plt.title(\"Prosperity Overview\", fontsize=14)  # Sets title\n",
    "    plt.ylabel(\"Value (Scaled)\", fontsize=12)  # Sets y-axis label\n",
    "    for i, v in enumerate(prosperity_values):  # Adds value labels\n",
    "        plt.text(i, v + 1, f\"{[df['Prosperity_Median Income ($)'].iloc[0]/1000, df['Prosperity_Home Ownership (%)'].iloc[0], df['Prosperity_Unemployment (%)'].iloc[0]][i]:.1f}\", ha='center')  # Labels bars\n",
    "    plt.savefig(\"prosperity_metrics.png\")  # Saves bar chart\n",
    "    plt.close()  # Closes figure\n",
    "\n",
    "    plt.figure(figsize=(6, 6))  # Sets figure size for finance\n",
    "    plt.bar([\"Grants Proxy (per 1000)\"], [df[\"Finance_Grants Proxy (per 1000)\"].iloc[0]], color='#00CC99')  # Plots finance bar\n",
    "    plt.title(\"Finance Overview\", fontsize=14)  # Sets title\n",
    "    plt.ylabel(\"Grants per 1000\", fontsize=12)  # Sets y-axis label\n",
    "    plt.text(0, df[\"Finance_Grants Proxy (per 1000)\"].iloc[0] + 0.5, f\"{df['Finance_Grants Proxy (per 1000)'].iloc[0]}\", ha='center')  # Adds value label\n",
    "    plt.savefig(\"finance_metric.png\")  # Saves bar chart\n",
    "    plt.close()  # Closes figure\n",
    "\n",
    "    plt.figure(figsize=(12, 6))  # Sets figure size for scores\n",
    "    categories = [\"Identity\", \"Connectivity\", \"Wellness\", \"Prosperity\", \"Finance\"]  # Defines score categories\n",
    "    scores = [df[\"Identity_Score\"].iloc[0], df[\"Connectivity_Score\"].iloc[0], df[\"Wellness_Score\"].iloc[0], df[\"Prosperity_Score\"].iloc[0], df[\"Finance_Score\"].iloc[0]]  # Gets scores\n",
    "    plt.bar(categories, scores, color=['#FF9999', '#66B2FF', '#CC33FF', '#FF9900', '#00CC99'])  # Plots bar chart\n",
    "    plt.title(\"Overall Impact Scores\", fontsize=14)  # Sets title\n",
    "    plt.ylabel(\"Score (0-100)\", fontsize=12)  # Sets y-axis label\n",
    "    plt.ylim(0, 100)  # Sets y-axis range\n",
    "    for i, v in enumerate(scores):  # Adds score labels\n",
    "        plt.text(i, v + 2, f\"{v:.1f}\", ha='center')  # Labels bars\n",
    "    plt.savefig(\"overall_scores.png\")  # Saves bar chart\n",
    "    plt.close()  # Closes figure\n",
    "    print(\"Graphs saved as PNG files: identity_diversity.png, connectivity_metrics.png, wellness_metrics.png, prosperity_metrics.png, finance_metric.png, overall_scores.png\")  # Logs saved files\n",
    "\n",
    "if __name__ == \"__main__\":  # Runs if script is main\n",
    "    address = input(\"Enter address: \")  # Takes user input for address\n",
    "    start_time = time.time()  # Starts timer\n",
    "    try:\n",
    "        result = automate_impact_tool(address)  # Runs impact tool\n",
    "        print(f\"Completed data collection in {time.time() - start_time:.2f} seconds\")  # Logs execution time\n",
    "        visualize_data(result)  # Generates visualizations\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to process request: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6504401c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter address: 123 Main St, Charlotte, NC\n",
      "Processing 123 Main St, Charlotte, NC...\n",
      "Geocoded 123 Main St, Charlotte, NC to (35.20854790943231, -80.8311796379137)\n",
      "Geocoding API response is successful\n",
      "Geocoded to State FIPS: 37, County FIPS: 119\n",
      "ACS5 API call successful for fields: ('NAME', 'B03002_003E', 'B03002_004E', 'B03002_012E', 'B01001_001E', 'B01002_001E', 'B05002_013E')\n",
      "Raw Census API response: [{'NAME': 'Mecklenburg County, North Carolina', 'B03002_003E': 501903.0, 'B03002_004E': 341395.0, 'B03002_012E': 150566.0, 'B01001_001E': 1100984.0, 'B01002_001E': 35.4, 'B05002_013E': 175619.0, 'state': '37', 'county': '119'}]\n",
      "Parks: 3, Bus Stops: 198\n",
      "Geocoding API response is successful\n",
      "Geocoded to State FIPS: 37, County FIPS: 119\n",
      "ACS5 API call successful for fields: ('B08301_010E', 'B01001_001E')\n",
      "Raw Census API response: [{'B08301_010E': 13387.0, 'B01001_001E': 1100984.0, 'state': '37', 'county': '119'}]\n",
      "ACS5 API call successful for fields: ('B18101_001E', 'B27001_028E', 'B01001_001E', 'C24050_026E')\n",
      "Raw Census API response: [{'B18101_001E': 1095629.0, 'B27001_028E': 17571.0, 'B01001_001E': 1100984.0, 'C24050_026E': 13110.0, 'state': '37', 'county': '119'}]\n",
      "ACS5 API call successful for fields: ('NAME', 'B19013_001E', 'B25003_002E', 'B23025_005E', 'B01001_001E')\n",
      "Raw Census API response: [{'NAME': 'Mecklenburg County, North Carolina', 'B19013_001E': 73124.0, 'B25003_002E': 245766.0, 'B23025_005E': 28741.0, 'B01001_001E': 1100984.0, 'state': '37', 'county': '119'}]\n",
      "ACS5 API call successful for fields: ('B01001_001E', 'C24050_001E')\n",
      "Raw Census API response: [{'B01001_001E': 1100984.0, 'C24050_001E': 591051.0, 'state': '37', 'county': '119'}]\n",
      "Scores: {'Identity': 74.0220566329756, 'Connectivity': 48.3349948533312, 'Wellness': 42.554824553810676, 'Prosperity': 85.254743956539, 'Finance': 80}\n",
      "Data saved to impact_tool_output.csv\n",
      "Geocoded to: (35.20854790943231, -80.8311796379137)\n",
      "Completed data collection in 59.34 seconds\n",
      "Graphs saved as PNG files: identity_diversity.png, connectivity_metrics.png, wellness_metrics.png, prosperity_metrics.png, finance_metric.png, overall_scores.png\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from geopy.geocoders import Nominatim\n",
    "from geopy.extra.rate_limiter import RateLimiter\n",
    "import pandas as pd\n",
    "from census import Census\n",
    "import time\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Constants\n",
    "CENSUS_API_KEY = \"86cfe7a999f6607864204747a5ac83b7c77e02fb\"\n",
    "RADIUS = 5\n",
    "BASE_YEAR = 2021\n",
    "\n",
    "geolocator = Nominatim(user_agent=\"impact_tool\")\n",
    "geocode = RateLimiter(geolocator.geocode, min_delay_seconds=1, max_retries=3, error_wait_seconds=5)\n",
    "c = Census(CENSUS_API_KEY, year=BASE_YEAR)\n",
    "census_cache = {}\n",
    "\n",
    "def geocode_address(address):\n",
    "    location = geocode(address, timeout=10)\n",
    "    if location:\n",
    "        print(f\"Geocoded {address} to ({location.latitude}, {location.longitude})\")\n",
    "        return location.latitude, location.longitude\n",
    "    raise ValueError(f\"Address not found: {address}\")\n",
    "\n",
    "def get_county_fips(lat, lon):\n",
    "    url = f\"https://geocoding.geo.census.gov/geocoder/geographies/coordinates?x={lon}&y={lat}&benchmark=Public_AR_Current&vintage=Current_Current&format=json\"\n",
    "    try:\n",
    "        response = requests.get(url, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        print(\"Geocoding API response is successful\")\n",
    "        county = data[\"result\"][\"geographies\"][\"Counties\"][0]\n",
    "        state_fips = county[\"GEOID\"][:2]\n",
    "        county_fips = county[\"GEOID\"][-3:]\n",
    "        print(f\"Geocoded to State FIPS: {state_fips}, County FIPS: {county_fips}\")\n",
    "        return state_fips, county_fips\n",
    "    except (requests.RequestException, KeyError, IndexError) as e:\n",
    "        raise ValueError(f\"Failed to fetch FIPS codes for coordinates ({lat}, {lon}): {str(e)}\")\n",
    "\n",
    "def fetch_census_data(fields, state_fips, county_fips):\n",
    "    cache_key = (county_fips, tuple(fields))\n",
    "    if cache_key in census_cache:\n",
    "        print(f\"Using cached data for {fields}\")\n",
    "        return census_cache[cache_key]\n",
    "    try:\n",
    "        response = c.acs5.state_county(fields, state_fips, county_fips)\n",
    "        print(f\"ACS5 API call successful for fields: {fields}\")\n",
    "        print(f\"Raw Census API response: {response}\")\n",
    "        data = response[0] if response else None\n",
    "        if not data:\n",
    "            raise ValueError(\"No data returned from Census API\")\n",
    "        census_cache[cache_key] = data\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        print(f\"Census library error: {e}\")\n",
    "        url = f\"https://api.census.gov/data/{BASE_YEAR}/acs/acs5?get={','.join(fields)}&for=county:{county_fips}&in=state:{state_fips}&key={CENSUS_API_KEY}\"\n",
    "        try:\n",
    "            response = requests.get(url, timeout=10)\n",
    "            response.raise_for_status()\n",
    "            data = response.json()\n",
    "            print(f\"Direct Census API response: {data}\")\n",
    "            data = dict(zip(data[0], data[1])) if len(data) > 1 else None\n",
    "            if not data:\n",
    "                raise ValueError(\"No data returned from direct Census API\")\n",
    "            census_cache[cache_key] = data\n",
    "            return data\n",
    "        except requests.RequestException as e:\n",
    "            raise ValueError(f\"Failed to fetch Census data for fields {fields}: {str(e)}\")\n",
    "\n",
    "def scrape_identity(county_fips, state_fips):\n",
    "    data = fetch_census_data((\"NAME\", \"B03002_003E\", \"B03002_004E\", \"B03002_012E\", \"B01001_001E\", \"B01002_001E\", \"B05002_013E\"), state_fips, county_fips)\n",
    "    total_pop = float(data[\"B01001_001E\"])\n",
    "    diversity = {\n",
    "        \"White\": float(data[\"B03002_003E\"]) / total_pop * 100,\n",
    "        \"Black\": float(data[\"B03002_004E\"]) / total_pop * 100,\n",
    "        \"Hispanic\": float(data[\"B03002_012E\"]) / total_pop * 100,\n",
    "        \"Foreign Born\": float(data[\"B05002_013E\"]) / total_pop * 100,\n",
    "        \"Median Age\": float(data[\"B01002_001E\"])\n",
    "    }\n",
    "    score = min(100, 100 - ((diversity[\"White\"] - 30) / 30 * 50))\n",
    "    return {\"Diversity\": diversity, \"Score\": score}\n",
    "\n",
    "def scrape_connectivity(lat, lon):\n",
    "    try:\n",
    "        osm_park_url = f\"https://overpass-api.de/api/interpreter?data=[out:json];node(around:{RADIUS*1609.34},{lat},{lon})[leisure=park];out;\"\n",
    "        park_response = requests.get(osm_park_url, timeout=10).json()\n",
    "        parks = len(park_response[\"elements\"])\n",
    "        park_access = min(50, parks * 5)\n",
    "        osm_bus_url = f\"https://overpass-api.de/api/interpreter?data=[out:json];node(around:{RADIUS*1609.34},{lat},{lon})[highway=bus_stop];out;\"\n",
    "        bus_response = requests.get(osm_bus_url, timeout=10).json()\n",
    "        bus_stops = len(bus_response[\"elements\"])\n",
    "        print(f\"Parks: {parks}, Bus Stops: {bus_stops}\")\n",
    "        state_fips, county_fips = get_county_fips(lat, lon)\n",
    "        data = fetch_census_data((\"B08301_010E\", \"B01001_001E\"), state_fips, county_fips)\n",
    "        transit_pct = float(data[\"B08301_010E\"]) / float(data[\"B01001_001E\"]) * 100\n",
    "        score = min(100, ((park_access / 50 * 30) + (bus_stops / 200 * 30) + (transit_pct / 2 * 40)) * 0.767)\n",
    "        return {\"Park Access (%)\": park_access, \"Bus Stops\": bus_stops, \"Transit (%)\": transit_pct, \"Score\": score}\n",
    "    except Exception as e:\n",
    "        print(f\"Error in scrape_connectivity: {e}\")\n",
    "        raise\n",
    "\n",
    "def scrape_wellness(county_fips, state_fips):\n",
    "    data = fetch_census_data((\"B18101_001E\", \"B27001_028E\", \"B01001_001E\", \"C24050_026E\"), state_fips, county_fips)\n",
    "    total_pop = float(data[\"B01001_001E\"])\n",
    "    uninsured = float(data[\"B27001_028E\"]) / total_pop * 100\n",
    "    provider_ratio = float(data[\"B01001_001E\"]) / float(data[\"C24050_026E\"]) if float(data[\"C24050_026E\"]) > 0 else 1000\n",
    "    score = min(100, (100 - ((uninsured - 10) * 3) + ((300 - provider_ratio) / 10)) / 3.45)\n",
    "    return {\"Obesity Proxy (%)\": 0.0, \"Uninsured (%)\": uninsured, \"Provider Ratio\": provider_ratio, \"Score\": score}\n",
    "\n",
    "def scrape_prosperity(county_fips, state_fips):\n",
    "    data = fetch_census_data((\"NAME\", \"B19013_001E\", \"B25003_002E\", \"B23025_005E\", \"B01001_001E\"), state_fips, county_fips)\n",
    "    total_pop = float(data[\"B01001_001E\"])\n",
    "    income = float(data[\"B19013_001E\"])\n",
    "    home_ownership = float(data[\"B25003_002E\"]) / total_pop * 100\n",
    "    unemployment = float(data[\"B23025_005E\"]) / total_pop * 100\n",
    "    score = min(100, ((income / 60000) * 61.5) + ((home_ownership / 65) * 30))\n",
    "    return {\"Median Income ($)\": income, \"Home Ownership (%)\": home_ownership, \"Unemployment (%)\": unemployment, \"Score\": score}\n",
    "\n",
    "def scrape_finance(county_fips, state_fips):\n",
    "    data = fetch_census_data((\"B01001_001E\", \"C24050_001E\"), state_fips, county_fips)\n",
    "    total_pop = float(data[\"B01001_001E\"])\n",
    "    biz_activity = float(data[\"C24050_001E\"]) / total_pop * 1000\n",
    "    grants_proxy = min(10, biz_activity / 50)\n",
    "    score = min(100, grants_proxy * 8)\n",
    "    return {\"Grants Proxy (per 1000)\": grants_proxy, \"Score\": score}\n",
    "\n",
    "def automate_impact_tool(address):\n",
    "    print(f\"Processing {address}...\")\n",
    "    try:\n",
    "        lat, lon = geocode_address(address)\n",
    "        state_fips, county_fips = get_county_fips(lat, lon)\n",
    "        data = {\n",
    "            \"Identity\": scrape_identity(county_fips, state_fips),\n",
    "            \"Connectivity\": scrape_connectivity(lat, lon),\n",
    "            \"Wellness\": scrape_wellness(county_fips, state_fips),\n",
    "            \"Prosperity\": scrape_prosperity(county_fips, state_fips),\n",
    "            \"Finance\": scrape_finance(county_fips, state_fips)\n",
    "        }\n",
    "        flat_data = {}\n",
    "        for category, values in data.items():\n",
    "            for key, val in values.items():\n",
    "                flat_data[f\"{category}_{key}\"] = val\n",
    "        df = pd.DataFrame([flat_data])\n",
    "        print(\"Scores:\", {k: v[\"Score\"] for k, v in data.items()})\n",
    "        df.to_csv(\"impact_tool_output.csv\", index=False)\n",
    "        print(\"Data saved to impact_tool_output.csv\")\n",
    "        print(f\"Geocoded to: ({lat}, {lon})\")\n",
    "        return df\n",
    "    except ValueError as e:\n",
    "        print(f\"Error processing request: {e}\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error: {e}\")\n",
    "        raise\n",
    "\n",
    "def visualize_data(df):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    diversity = df[\"Identity_Diversity\"].iloc[0]\n",
    "    plt.pie([diversity[\"White\"], diversity[\"Black\"], diversity[\"Hispanic\"], diversity[\"Foreign Born\"]], \n",
    "            labels=[\"White\", \"Black\", \"Hispanic\", \"Foreign Born\"], autopct='%1.1f%%', \n",
    "            startangle=90, colors=['#FF9999', '#66B2FF', '#99FF99', '#FFCC99'])\n",
    "    plt.title(\"Community Diversity\", fontsize=14)\n",
    "    plt.axis('equal')\n",
    "    plt.savefig(\"identity_diversity.png\")\n",
    "    plt.close()\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    connectivity_metrics = [\"Park Access (%)\", \"Bus Stops\", \"Transit (%)\"]\n",
    "    connectivity_values = [df[\"Connectivity_Park Access (%)\"].iloc[0], \n",
    "                         df[\"Connectivity_Bus Stops\"].iloc[0] / 10, \n",
    "                         df[\"Connectivity_Transit (%)\"].iloc[0] * 10]\n",
    "    plt.bar(connectivity_metrics, connectivity_values, color=['#FFCC00', '#00CC66', '#0066CC'])\n",
    "    plt.title(\"Connectivity Overview\", fontsize=14)\n",
    "    plt.ylabel(\"Value (Scaled)\", fontsize=12)\n",
    "    for i, v in enumerate(connectivity_values):\n",
    "        plt.text(i, v + 1, f\"{[df['Connectivity_Park Access (%)'].iloc[0], df['Connectivity_Bus Stops'].iloc[0], df['Connectivity_Transit (%)'].iloc[0]][i]}\", ha='center')\n",
    "    plt.savefig(\"connectivity_metrics.png\")\n",
    "    plt.close()\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    wellness_metrics = [\"Uninsured (%)\", \"Provider Ratio\"]\n",
    "    wellness_values = [df[\"Wellness_Uninsured (%)\"].iloc[0] * 10, \n",
    "                      df[\"Wellness_Provider Ratio\"].iloc[0] / 5]\n",
    "    plt.bar(wellness_metrics, wellness_values, color=['#FF33CC', '#33CCCC'])\n",
    "    plt.title(\"Wellness Overview\", fontsize=14)\n",
    "    plt.ylabel(\"Value (Scaled)\", fontsize=12)\n",
    "    for i, v in enumerate(wellness_values):\n",
    "        plt.text(i, v + 1, f\"{[df['Wellness_Uninsured (%)'].iloc[0], df['Wellness_Provider Ratio'].iloc[0]][i]:.1f}\", ha='center')\n",
    "    plt.savefig(\"wellness_metrics.png\")\n",
    "    plt.close()\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    prosperity_metrics = [\"Median Income ($K)\", \"Home Ownership (%)\", \"Unemployment (%)\"]\n",
    "    prosperity_values = [df[\"Prosperity_Median Income ($)\"].iloc[0] / 1000, \n",
    "                        df[\"Prosperity_Home Ownership (%)\"].iloc[0], \n",
    "                        df[\"Prosperity_Unemployment (%)\"].iloc[0] * 10]\n",
    "    plt.bar(prosperity_metrics, prosperity_values, color=['#FF9900', '#0099FF', '#CC0000'])\n",
    "    plt.title(\"Prosperity Overview\", fontsize=14)\n",
    "    plt.ylabel(\"Value (Scaled)\", fontsize=12)\n",
    "    for i, v in enumerate(prosperity_values):\n",
    "        plt.text(i, v + 1, f\"{[df['Prosperity_Median Income ($)'].iloc[0]/1000, df['Prosperity_Home Ownership (%)'].iloc[0], df['Prosperity_Unemployment (%)'].iloc[0]][i]:.1f}\", ha='center')\n",
    "    plt.savefig(\"prosperity_metrics.png\")\n",
    "    plt.close()\n",
    "\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.bar([\"Grants Proxy (per 1000)\"], [df[\"Finance_Grants Proxy (per 1000)\"].iloc[0]], color='#00CC99')\n",
    "    plt.title(\"Finance Overview\", fontsize=14)\n",
    "    plt.ylabel(\"Grants per 1000\", fontsize=12)\n",
    "    plt.text(0, df[\"Finance_Grants Proxy (per 1000)\"].iloc[0] + 0.5, \n",
    "             f\"{df['Finance_Grants Proxy (per 1000)'].iloc[0]}\", ha='center')\n",
    "    plt.savefig(\"finance_metric.png\")\n",
    "    plt.close()\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    categories = [\"Identity\", \"Connectivity\", \"Wellness\", \"Prosperity\", \"Finance\"]\n",
    "    scores = [df[\"Identity_Score\"].iloc[0], df[\"Connectivity_Score\"].iloc[0], \n",
    "              df[\"Wellness_Score\"].iloc[0], df[\"Prosperity_Score\"].iloc[0], \n",
    "              df[\"Finance_Score\"].iloc[0]]\n",
    "    plt.bar(categories, scores, color=['#FF9999', '#66B2FF', '#CC33FF', '#FF9900', '#00CC99'])\n",
    "    plt.title(\"Overall Impact Scores\", fontsize=14)\n",
    "    plt.ylabel(\"Score (0-100)\", fontsize=12)\n",
    "    plt.ylim(0, 100)\n",
    "    for i, v in enumerate(scores):\n",
    "        plt.text(i, v + 2, f\"{v:.1f}\", ha='center')\n",
    "    plt.savefig(\"overall_scores.png\")\n",
    "    plt.close()\n",
    "    print(\"Graphs saved as PNG files: identity_diversity.png, connectivity_metrics.png, wellness_metrics.png, prosperity_metrics.png, finance_metric.png, overall_scores.png\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    address = input(\"Enter address: \")\n",
    "    start_time = time.time()\n",
    "    try:\n",
    "        result = automate_impact_tool(address)\n",
    "        print(f\"Completed data collection in {time.time() - start_time:.2f} seconds\")\n",
    "        visualize_data(result)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to process request: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e1fdd807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter address: 123 Main St, Charlotte, NC\n",
      "Processing 123 Main St, Charlotte, NC...\n",
      "Geocoded 123 Main St, Charlotte, NC to (35.20854790943231, -80.8311796379137)\n",
      "Geocoding API response is successful\n",
      "Geocoded to State FIPS: 37, County FIPS: 119\n",
      "Using existing nc_county_data.xlsx\n",
      "Using Mecklenburg cache for ('NAME', 'B03002_003E', 'B03002_004E', 'B03002_012E', 'B01001_001E', 'B01002_001E', 'B05002_013E')\n",
      "Calculated medians: {'White (%)': 67.3887521566493, 'Black (%)': 17.767609179573636, 'Hispanic (%)': 6.8423496082637225, 'Foreign Born (%)': 3.8914497825014154, 'Park Access': 1.4966990336264674, 'Bus Stops': 7.483495168132338, 'Transit (%)': 0.07483495168132337, 'Uninsured (%)': 3.074482984159226, 'Provider Ratio': 157.96463166891695, 'Median Income ($)': 51497.0, 'Home Ownership (%)': 28.471411394017153, 'Unemployment (%)': 2.596609445713743, 'Grants Proxy (per 1000)': 8.696259228740153}\n",
      "Parks: 3, Bus Stops: 198\n",
      "Geocoding API response is successful\n",
      "Geocoded to State FIPS: 37, County FIPS: 119\n",
      "Using Mecklenburg cache for ('B08301_010E', 'B01001_001E')\n",
      "Calculated medians: {'White (%)': 67.3887521566493, 'Black (%)': 17.767609179573636, 'Hispanic (%)': 6.8423496082637225, 'Foreign Born (%)': 3.8914497825014154, 'Park Access': 1.4966990336264674, 'Bus Stops': 7.483495168132338, 'Transit (%)': 0.07483495168132337, 'Uninsured (%)': 3.074482984159226, 'Provider Ratio': 157.96463166891695, 'Median Income ($)': 51497.0, 'Home Ownership (%)': 28.471411394017153, 'Unemployment (%)': 2.596609445713743, 'Grants Proxy (per 1000)': 8.696259228740153}\n",
      "Using Mecklenburg cache for ('B18101_001E', 'B27001_028E', 'B01001_001E', 'C24050_026E')\n",
      "Calculated medians: {'White (%)': 67.3887521566493, 'Black (%)': 17.767609179573636, 'Hispanic (%)': 6.8423496082637225, 'Foreign Born (%)': 3.8914497825014154, 'Park Access': 1.4966990336264674, 'Bus Stops': 7.483495168132338, 'Transit (%)': 0.07483495168132337, 'Uninsured (%)': 3.074482984159226, 'Provider Ratio': 157.96463166891695, 'Median Income ($)': 51497.0, 'Home Ownership (%)': 28.471411394017153, 'Unemployment (%)': 2.596609445713743, 'Grants Proxy (per 1000)': 8.696259228740153}\n",
      "Using Mecklenburg cache for ('NAME', 'B19013_001E', 'B25003_002E', 'B23025_005E', 'B01001_001E')\n",
      "Calculated medians: {'White (%)': 67.3887521566493, 'Black (%)': 17.767609179573636, 'Hispanic (%)': 6.8423496082637225, 'Foreign Born (%)': 3.8914497825014154, 'Park Access': 1.4966990336264674, 'Bus Stops': 7.483495168132338, 'Transit (%)': 0.07483495168132337, 'Uninsured (%)': 3.074482984159226, 'Provider Ratio': 157.96463166891695, 'Median Income ($)': 51497.0, 'Home Ownership (%)': 28.471411394017153, 'Unemployment (%)': 2.596609445713743, 'Grants Proxy (per 1000)': 8.696259228740153}\n",
      "Using Mecklenburg cache for ('B01001_001E', 'C24050_001E')\n",
      "Calculated medians: {'White (%)': 67.3887521566493, 'Black (%)': 17.767609179573636, 'Hispanic (%)': 6.8423496082637225, 'Foreign Born (%)': 3.8914497825014154, 'Park Access': 1.4966990336264674, 'Bus Stops': 7.483495168132338, 'Transit (%)': 0.07483495168132337, 'Uninsured (%)': 3.074482984159226, 'Provider Ratio': 157.96463166891695, 'Median Income ($)': 51497.0, 'Home Ownership (%)': 28.471411394017153, 'Unemployment (%)': 2.596609445713743, 'Grants Proxy (per 1000)': 8.696259228740153}\n",
      "Scores: {'Identity': 94.57534533757936, 'Connectivity': 100.0, 'Wellness': 75.88877461231723, 'Prosperity': 61.42687370083369, 'Finance': 63.037407712598466}\n",
      "Data saved to impact_tool_output.csv\n",
      "Geocoded to: (35.20854790943231, -80.8311796379137)\n",
      "Completed data collection in 53.26 seconds\n",
      "Graphs saved: identity_diversity.png, connectivity_metrics.png, wellness_metrics.png, prosperity_metrics.png, finance_metric.png, category_scores.png, overall_scores.png\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from geopy.geocoders import Nominatim\n",
    "from geopy.extra.rate_limiter import RateLimiter\n",
    "import pandas as pd\n",
    "from census import Census\n",
    "import time\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import statistics\n",
    "import json\n",
    "\n",
    "# Constants\n",
    "CENSUS_API_KEY = \"86cfe7a999f6607864204747a5ac83b7c77e02fb\"\n",
    "RADIUS = 5\n",
    "BASE_YEAR = 2021\n",
    "TIMEOUT = 30\n",
    "MAX_RETRIES = 3\n",
    "\n",
    "geolocator = Nominatim(user_agent=\"impact_tool\")\n",
    "geocode = RateLimiter(geolocator.geocode, min_delay_seconds=1, max_retries=3, error_wait_seconds=5)\n",
    "c = Census(CENSUS_API_KEY, year=BASE_YEAR)\n",
    "census_cache = {}\n",
    "mecklenburg_cache_file = \"mecklenburg_cache.json\"\n",
    "\n",
    "def load_mecklenburg_cache():\n",
    "    try:\n",
    "        if os.path.exists(mecklenburg_cache_file):\n",
    "            with open(mecklenburg_cache_file, 'r') as f:\n",
    "                return json.load(f)\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error reading cache file: {e}. Starting with empty cache.\")\n",
    "        if os.path.exists(mecklenburg_cache_file):\n",
    "            os.remove(mecklenburg_cache_file)\n",
    "    return {}\n",
    "\n",
    "def save_mecklenburg_cache(cache):\n",
    "    try:\n",
    "        with open(mecklenburg_cache_file, 'w') as f:\n",
    "            json.dump(cache, f, default=str)\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving cache: {e}\")\n",
    "\n",
    "def retry_with_backoff(func, *args, max_attempts=MAX_RETRIES, base_delay=1, max_delay=10):\n",
    "    for attempt in range(max_attempts):\n",
    "        try:\n",
    "            return func(*args)\n",
    "        except (requests.RequestException, ValueError) as e:\n",
    "            if attempt == max_attempts - 1:\n",
    "                raise\n",
    "            delay = min(base_delay * (2 ** attempt), max_delay)\n",
    "            print(f\"Attempt {attempt + 1} failed: {e}. Retrying after {delay}s...\")\n",
    "            time.sleep(delay)\n",
    "    raise ValueError(\"Max retries reached\")\n",
    "\n",
    "def geocode_address(address):\n",
    "    def _geocode():\n",
    "        location = geocode(address, timeout=TIMEOUT)\n",
    "        if location:\n",
    "            print(f\"Geocoded {address} to ({location.latitude}, {location.longitude})\")\n",
    "            return location.latitude, location.longitude\n",
    "        raise ValueError(f\"Address not found: {address}\")\n",
    "    return retry_with_backoff(_geocode)\n",
    "\n",
    "def get_county_fips(lat, lon):\n",
    "    def _get_fips():\n",
    "        url = f\"https://geocoding.geo.census.gov/geocoder/geographies/coordinates?x={lon}&y={lat}&benchmark=Public_AR_Current&vintage=Current_Current&format=json\"\n",
    "        response = requests.get(url, timeout=TIMEOUT)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        print(\"Geocoding API response is successful\")\n",
    "        county = data[\"result\"][\"geographies\"][\"Counties\"][0]\n",
    "        state_fips = county[\"GEOID\"][:2]\n",
    "        county_fips = county[\"GEOID\"][-3:]\n",
    "        print(f\"Geocoded to State FIPS: {state_fips}, County FIPS: {county_fips}\")\n",
    "        return state_fips, county_fips\n",
    "    return retry_with_backoff(_get_fips)\n",
    "\n",
    "def fetch_census_data(fields, state_fips, county_fips):\n",
    "    cache_key = f\"{county_fips}_{'_'.join(fields)}\"\n",
    "    meck_cache = load_mecklenburg_cache()\n",
    "    if cache_key in meck_cache:\n",
    "        print(f\"Using Mecklenburg cache for {fields}\")\n",
    "        return meck_cache[cache_key]\n",
    "    if cache_key in census_cache:\n",
    "        print(f\"Using global cache for {fields}\")\n",
    "        return census_cache[cache_key]\n",
    "    def _fetch():\n",
    "        try:\n",
    "            response = c.acs5.state_county(fields, state_fips, county_fips)\n",
    "            print(f\"ACS5 API call successful for fields: {fields}\")\n",
    "            data = response[0] if response else None\n",
    "            if not data:\n",
    "                raise ValueError(\"No data returned from Census API\")\n",
    "            return {k: str(v) for k, v in data.items()}\n",
    "        except Exception as e:\n",
    "            print(f\"Census library error: {e}\")\n",
    "            url = f\"https://api.census.gov/data/{BASE_YEAR}/acs/acs5?get={','.join(fields)}&for=county:{county_fips}&in=state:{state_fips}&key={CENSUS_API_KEY}\"\n",
    "            response = requests.get(url, timeout=TIMEOUT)\n",
    "            response.raise_for_status()\n",
    "            data = response.json()\n",
    "            print(f\"Direct Census API response: {data}\")\n",
    "            data = dict(zip(data[0], data[1])) if len(data) > 1 else None\n",
    "            if not data:\n",
    "                raise ValueError(\"No data returned from direct Census API\")\n",
    "            return {k: str(v) for k, v in data.items()}\n",
    "    data = retry_with_backoff(_fetch)\n",
    "    census_cache[cache_key] = data\n",
    "    if county_fips == \"119\" and state_fips == \"37\":\n",
    "        meck_cache[cache_key] = data\n",
    "        save_mecklenburg_cache(meck_cache)\n",
    "    return data\n",
    "\n",
    "def fetch_nc_county_data(state_fips):\n",
    "    if os.path.exists(\"nc_county_data.xlsx\"):\n",
    "        print(\"Using existing nc_county_data.xlsx\")\n",
    "        return pd.read_excel(\"nc_county_data.xlsx\")\n",
    "    fields = (\"NAME\", \"B03002_003E\", \"B03002_004E\", \"B03002_012E\", \"B05002_013E\", \n",
    "              \"B01001_001E\", \"B08301_010E\", \"B27001_028E\", \"C24050_026E\", \n",
    "              \"B19013_001E\", \"B25003_002E\", \"B23025_005E\", \"C24050_001E\")\n",
    "    nc_data = c.acs5.state_county(fields, state_fips, Census.ALL)\n",
    "    county_data = []\n",
    "    for d in nc_data:\n",
    "        pop = float(d[\"B01001_001E\"])\n",
    "        if pop > 0:\n",
    "            county = {\n",
    "                \"FIPS\": d[\"state\"] + d[\"county\"],\n",
    "                \"Name\": d[\"NAME\"],\n",
    "                \"White (%)\": float(d[\"B03002_003E\"]) / pop * 100,\n",
    "                \"Black (%)\": float(d[\"B03002_004E\"]) / pop * 100,\n",
    "                \"Hispanic (%)\": float(d[\"B03002_012E\"]) / pop * 100,\n",
    "                \"Foreign Born (%)\": float(d[\"B05002_013E\"]) / pop * 100,\n",
    "                \"Transit (%)\": float(d[\"B08301_010E\"]) / pop * 100,\n",
    "                \"Uninsured (%)\": float(d[\"B27001_028E\"]) / pop * 100,\n",
    "                \"Provider Ratio\": pop / float(d[\"C24050_026E\"]) if float(d[\"C24050_026E\"]) > 0 else 1000,\n",
    "                \"Median Income ($)\": float(d[\"B19013_001E\"]),\n",
    "                \"Home Ownership (%)\": float(d[\"B25003_002E\"]) / pop * 100,\n",
    "                \"Unemployment (%)\": float(d[\"B23025_005E\"]) / pop * 100,\n",
    "                \"Grants Proxy (per 1000)\": min(10, (float(d[\"C24050_001E\"]) / pop * 1000) / 50)\n",
    "            }\n",
    "            county[\"Park Access\"] = min(50, county[\"Transit (%)\"] * 20)\n",
    "            county[\"Bus Stops\"] = county[\"Transit (%)\"] * 100\n",
    "            county_data.append(county)\n",
    "    df = pd.DataFrame(county_data)\n",
    "    df.to_excel(\"nc_county_data.xlsx\", index=False)\n",
    "    print(\"Saved county data to nc_county_data.xlsx\")\n",
    "    return df\n",
    "\n",
    "def get_nc_medians():\n",
    "    try:\n",
    "        df = pd.read_excel(\"nc_county_data.xlsx\")\n",
    "        medians = {\n",
    "            \"White (%)\": df[\"White (%)\"].median(),\n",
    "            \"Black (%)\": df[\"Black (%)\"].median(),\n",
    "            \"Hispanic (%)\": df[\"Hispanic (%)\"].median(),\n",
    "            \"Foreign Born (%)\": df[\"Foreign Born (%)\"].median(),\n",
    "            \"Park Access\": df[\"Park Access\"].median(),\n",
    "            \"Bus Stops\": df[\"Bus Stops\"].median(),\n",
    "            \"Transit (%)\": df[\"Transit (%)\"].median(),\n",
    "            \"Uninsured (%)\": df[\"Uninsured (%)\"].median(),\n",
    "            \"Provider Ratio\": df[\"Provider Ratio\"].median(),\n",
    "            \"Median Income ($)\": df[\"Median Income ($)\"].median(),\n",
    "            \"Home Ownership (%)\": df[\"Home Ownership (%)\"].median(),\n",
    "            \"Unemployment (%)\": df[\"Unemployment (%)\"].median(),\n",
    "            \"Grants Proxy (per 1000)\": df[\"Grants Proxy (per 1000)\"].median()\n",
    "        }\n",
    "        print(f\"Calculated medians: {medians}\")\n",
    "        return medians\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading Excel: {e}, using fallback medians\")\n",
    "        return {\n",
    "            \"White (%)\": 60, \"Black (%)\": 20, \"Hispanic (%)\": 8, \"Foreign Born (%)\": 7,\n",
    "            \"Park Access\": 10, \"Bus Stops\": 50, \"Transit (%)\": 0.5,\n",
    "            \"Uninsured (%)\": 5, \"Provider Ratio\": 150,\n",
    "            \"Median Income ($)\": 55000, \"Home Ownership (%)\": 40, \"Unemployment (%)\": 4,\n",
    "            \"Grants Proxy (per 1000)\": 7\n",
    "        }\n",
    "\n",
    "def scrape_identity(county_fips, state_fips):\n",
    "    data = fetch_census_data((\"NAME\", \"B03002_003E\", \"B03002_004E\", \"B03002_012E\", \"B01001_001E\", \"B01002_001E\", \"B05002_013E\"), state_fips, county_fips)\n",
    "    total_pop = float(data[\"B01001_001E\"])\n",
    "    diversity = {\n",
    "        \"White\": float(data[\"B03002_003E\"]) / total_pop * 100,\n",
    "        \"Black\": float(data[\"B03002_004E\"]) / total_pop * 100,\n",
    "        \"Hispanic\": float(data[\"B03002_012E\"]) / total_pop * 100,\n",
    "        \"Foreign Born\": float(data[\"B05002_013E\"]) / total_pop * 100,\n",
    "        \"Median Age\": float(data[\"B01002_001E\"])\n",
    "    }\n",
    "    medians = get_nc_medians()\n",
    "    scores = {\n",
    "        \"White\": min(100, max(0, 50 + ((medians[\"White (%)\"] - diversity[\"White\"]) / 20 * 50))),\n",
    "        \"Black\": min(100, max(0, 50 + ((diversity[\"Black\"] - medians[\"Black (%)\"]) / 15 * 50))),\n",
    "        \"Hispanic\": min(100, max(0, 50 + ((diversity[\"Hispanic\"] - medians[\"Hispanic (%)\"]) / 10 * 50))),\n",
    "        \"Foreign Born\": min(100, max(0, 50 + ((diversity[\"Foreign Born\"] - medians[\"Foreign Born (%)\"]) / 8 * 50)))\n",
    "    }\n",
    "    score = sum(scores.values()) / len(scores)\n",
    "    return {\"Diversity\": diversity, \"Identity_Scores\": scores, \"Identity_Score\": score}\n",
    "\n",
    "def scrape_connectivity(lat, lon):\n",
    "    def _scrape():\n",
    "        osm_park_url = f\"https://overpass-api.de/api/interpreter?data=[out:json];node(around:{RADIUS*1609.34},{lat},{lon})[leisure=park];out;\"\n",
    "        park_response = requests.get(osm_park_url, timeout=TIMEOUT).json()\n",
    "        parks = len(park_response[\"elements\"])\n",
    "        park_access = min(50, parks * 5)\n",
    "        osm_bus_url = f\"https://overpass-api.de/api/interpreter?data=[out:json];node(around:{RADIUS*1609.34},{lat},{lon})[highway=bus_stop];out;\"\n",
    "        bus_response = requests.get(osm_bus_url, timeout=TIMEOUT).json()\n",
    "        bus_stops = len(bus_response[\"elements\"])\n",
    "        print(f\"Parks: {parks}, Bus Stops: {bus_stops}\")\n",
    "        state_fips, county_fips = get_county_fips(lat, lon)\n",
    "        data = fetch_census_data((\"B08301_010E\", \"B01001_001E\"), state_fips, county_fips)\n",
    "        transit_pct = float(data[\"B08301_010E\"]) / float(data[\"B01001_001E\"]) * 100\n",
    "        metrics = {\"Park Access\": park_access, \"Bus Stops\": bus_stops, \"Transit (%)\": transit_pct}\n",
    "        return metrics, state_fips, county_fips\n",
    "    metrics, state_fips, county_fips = retry_with_backoff(_scrape)\n",
    "    medians = get_nc_medians()\n",
    "    scores = {\n",
    "        \"Park Access\": min(100, max(0, 50 + ((metrics[\"Park Access\"] - medians[\"Park Access\"]) / 10 * 50))),\n",
    "        \"Bus Stops\": min(100, max(0, 50 + ((metrics[\"Bus Stops\"] - medians[\"Bus Stops\"]) / 50 * 50))),\n",
    "        \"Transit (%)\": min(100, max(0, 50 + ((metrics[\"Transit (%)\"] - medians[\"Transit (%)\"]) / 1 * 50)))\n",
    "    }\n",
    "    score = sum(scores.values()) / len(scores)\n",
    "    return {\"Park Access (%)\": metrics[\"Park Access\"], \"Bus Stops\": metrics[\"Bus Stops\"], \"Transit (%)\": metrics[\"Transit (%)\"], \"Connectivity_Scores\": scores, \"Connectivity_Score\": score}\n",
    "\n",
    "def scrape_wellness(county_fips, state_fips):\n",
    "    data = fetch_census_data((\"B18101_001E\", \"B27001_028E\", \"B01001_001E\", \"C24050_026E\"), state_fips, county_fips)\n",
    "    total_pop = float(data[\"B01001_001E\"])\n",
    "    uninsured = float(data[\"B27001_028E\"]) / total_pop * 100\n",
    "    provider_ratio = float(data[\"B01001_001E\"]) / float(data[\"C24050_026E\"]) if float(data[\"C24050_026E\"]) > 0 else 1000\n",
    "    metrics = {\"Uninsured (%)\": uninsured, \"Provider Ratio\": provider_ratio}\n",
    "    medians = get_nc_medians()\n",
    "    scores = {\n",
    "        \"Uninsured (%)\": min(100, max(0, 50 + ((medians[\"Uninsured (%)\"] - uninsured) / 5 * 50))),\n",
    "        \"Provider Ratio\": min(100, max(0, 50 + ((medians[\"Provider Ratio\"] - provider_ratio) / 100 * 50)))\n",
    "    }\n",
    "    score = sum(scores.values()) / len(scores)\n",
    "    return {\"Obesity Proxy (%)\": 0.0, \"Uninsured (%)\": uninsured, \"Provider Ratio\": provider_ratio, \"Wellness_Scores\": scores, \"Wellness_Score\": score}\n",
    "\n",
    "def scrape_prosperity(county_fips, state_fips):\n",
    "    data = fetch_census_data((\"NAME\", \"B19013_001E\", \"B25003_002E\", \"B23025_005E\", \"B01001_001E\"), state_fips, county_fips)\n",
    "    total_pop = float(data[\"B01001_001E\"])\n",
    "    income = float(data[\"B19013_001E\"])\n",
    "    home_ownership = float(data[\"B25003_002E\"]) / total_pop * 100\n",
    "    unemployment = float(data[\"B23025_005E\"]) / total_pop * 100\n",
    "    metrics = {\"Median Income ($)\": income, \"Home Ownership (%)\": home_ownership, \"Unemployment (%)\": unemployment}\n",
    "    medians = get_nc_medians()\n",
    "    scores = {\n",
    "        \"Median Income ($)\": min(100, max(0, 50 + ((income - medians[\"Median Income ($)\"]) / 20000 * 50))),\n",
    "        \"Home Ownership (%)\": min(100, max(0, 50 + ((home_ownership - medians[\"Home Ownership (%)\"]) / 20 * 50))),\n",
    "        \"Unemployment (%)\": min(100, max(0, 50 + ((medians[\"Unemployment (%)\"] - unemployment) / 2 * 50)))\n",
    "    }\n",
    "    score = sum(scores.values()) / len(scores)\n",
    "    return {\"Median Income ($)\": income, \"Home Ownership (%)\": home_ownership, \"Unemployment (%)\": unemployment, \"Prosperity_Scores\": scores, \"Prosperity_Score\": score}\n",
    "\n",
    "def scrape_finance(county_fips, state_fips):\n",
    "    data = fetch_census_data((\"B01001_001E\", \"C24050_001E\"), state_fips, county_fips)\n",
    "    total_pop = float(data[\"B01001_001E\"])\n",
    "    biz_activity = float(data[\"C24050_001E\"]) / total_pop * 1000\n",
    "    grants_proxy = min(10, biz_activity / 50)\n",
    "    metrics = {\"Grants Proxy (per 1000)\": grants_proxy}\n",
    "    medians = get_nc_medians()\n",
    "    scores = {\n",
    "        \"Grants Proxy (per 1000)\": min(100, max(0, 50 + ((grants_proxy - medians[\"Grants Proxy (per 1000)\"]) / 5 * 50)))\n",
    "    }\n",
    "    score = scores[\"Grants Proxy (per 1000)\"]\n",
    "    return {\"Grants Proxy (per 1000)\": grants_proxy, \"Finance_Scores\": scores, \"Finance_Score\": score}\n",
    "\n",
    "def automate_impact_tool(address):\n",
    "    print(f\"Processing {address}...\")\n",
    "    try:\n",
    "        lat, lon = geocode_address(address)\n",
    "        state_fips, county_fips = get_county_fips(lat, lon)\n",
    "        fetch_nc_county_data(state_fips)\n",
    "        data = {\n",
    "            \"Identity\": scrape_identity(county_fips, state_fips),\n",
    "            \"Connectivity\": scrape_connectivity(lat, lon),\n",
    "            \"Wellness\": scrape_wellness(county_fips, state_fips),\n",
    "            \"Prosperity\": scrape_prosperity(county_fips, state_fips),\n",
    "            \"Finance\": scrape_finance(county_fips, state_fips)\n",
    "        }\n",
    "        flat_data = {}\n",
    "        for category in data:\n",
    "            for key, val in data[category].items():\n",
    "                flat_data[f\"{category}_{key}\"] = val\n",
    "        df = pd.DataFrame([flat_data])\n",
    "        print(\"Scores:\", {k: v[f\"{k}_Score\"] for k, v in data.items()})\n",
    "        df.to_csv(\"impact_tool_output.csv\", index=False)\n",
    "        print(\"Data saved to impact_tool_output.csv\")\n",
    "        print(f\"Geocoded to: ({lat}, {lon})\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing request: {e}\")\n",
    "        raise\n",
    "\n",
    "def visualize_data(df):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    diversity = df[\"Identity_Diversity\"].iloc[0]\n",
    "    plt.pie([diversity[\"White\"], diversity[\"Black\"], diversity[\"Hispanic\"], diversity[\"Foreign Born\"]], \n",
    "            labels=[\"White\", \"Black\", \"Hispanic\", \"Foreign Born\"], autopct='%1.1f%%', \n",
    "            startangle=90, colors=['#FF9999', '#66B2FF', '#99FF99', '#FFCC99'])\n",
    "    plt.title(\"Community Diversity\", fontsize=14)\n",
    "    plt.axis('equal')\n",
    "    plt.savefig(\"identity_diversity.png\")\n",
    "    plt.close()\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    connectivity_metrics = [\"Park Access\", \"Bus Stops\", \"Transit (%)\"]\n",
    "    connectivity_values = [df[\"Connectivity_Park Access (%)\"].iloc[0], \n",
    "                         df[\"Connectivity_Bus Stops\"].iloc[0], \n",
    "                         df[\"Connectivity_Transit (%)\"].iloc[0]]\n",
    "    plt.bar(connectivity_metrics, connectivity_values, color=['#FFCC00', '#00CC66', '#0066CC'])\n",
    "    plt.title(\"Connectivity Overview\", fontsize=14)\n",
    "    plt.ylabel(\"Value\", fontsize=12)\n",
    "    for i, v in enumerate(connectivity_values):\n",
    "        plt.text(i, v + max(connectivity_values) * 0.05, f\"{v:.1f}\", ha='center')\n",
    "    plt.savefig(\"connectivity_metrics.png\")\n",
    "    plt.close()\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    wellness_metrics = [\"Uninsured (%)\", \"Provider Ratio\"]\n",
    "    wellness_values = [df[\"Wellness_Uninsured (%)\"].iloc[0], \n",
    "                      df[\"Wellness_Provider Ratio\"].iloc[0]]\n",
    "    plt.bar(wellness_metrics, wellness_values, color=['#FF33CC', '#33CCCC'])\n",
    "    plt.title(\"Wellness Overview\", fontsize=14)\n",
    "    plt.ylabel(\"Value\", fontsize=12)\n",
    "    for i, v in enumerate(wellness_values):\n",
    "        plt.text(i, v + max(wellness_values) * 0.05, f\"{v:.1f}\", ha='center')\n",
    "    plt.savefig(\"wellness_metrics.png\")\n",
    "    plt.close()\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    prosperity_metrics = [\"Median Income ($K)\", \"Home Ownership (%)\", \"Unemployment (%)\"]\n",
    "    prosperity_values = [df[\"Prosperity_Median Income ($)\"].iloc[0] / 1000, \n",
    "                        df[\"Prosperity_Home Ownership (%)\"].iloc[0], \n",
    "                        df[\"Prosperity_Unemployment (%)\"].iloc[0]]\n",
    "    plt.bar(prosperity_metrics, prosperity_values, color=['#FF9900', '#0099FF', '#CC0000'])\n",
    "    plt.title(\"Prosperity Overview\", fontsize=14)\n",
    "    plt.ylabel(\"Value\", fontsize=12)\n",
    "    for i, v in enumerate(prosperity_values):\n",
    "        plt.text(i, v + max(prosperity_values) * 0.05, f\"{v:.1f}\", ha='center')\n",
    "    plt.savefig(\"prosperity_metrics.png\")\n",
    "    plt.close()\n",
    "\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.bar([\"Grants Proxy (per 1000)\"], [df[\"Finance_Grants Proxy (per 1000)\"].iloc[0]], color='#00CC99')\n",
    "    plt.title(\"Finance Overview\", fontsize=14)\n",
    "    plt.ylabel(\"Grants per 1000\", fontsize=12)\n",
    "    plt.text(0, df[\"Finance_Grants Proxy (per 1000)\"].iloc[0] + 0.5, \n",
    "             f\"{df['Finance_Grants Proxy (per 1000)'].iloc[0]:.1f}\", ha='center')\n",
    "    plt.savefig(\"finance_metric.png\")\n",
    "    plt.close()\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    categories = [\"Identity\", \"Connectivity\", \"Wellness\", \"Prosperity\", \"Finance\"]\n",
    "    scores = [df[\"Identity_Identity_Score\"].iloc[0], df[\"Connectivity_Connectivity_Score\"].iloc[0], \n",
    "              df[\"Wellness_Wellness_Score\"].iloc[0], df[\"Prosperity_Prosperity_Score\"].iloc[0], \n",
    "              df[\"Finance_Finance_Score\"].iloc[0]]\n",
    "    plt.bar(categories, scores, color=['#FF9999', '#66B2FF', '#CC33FF', '#FF9900', '#00CC99'])\n",
    "    plt.title(\"Category Impact Scores\", fontsize=14)\n",
    "    plt.ylabel(\"Score (0-100)\", fontsize=12)\n",
    "    plt.ylim(0, 100)\n",
    "    for i, v in enumerate(scores):\n",
    "        plt.text(i, v + 2, f\"{v:.1f}\", ha='center')\n",
    "    plt.savefig(\"category_scores.png\")\n",
    "    plt.close()\n",
    "\n",
    "    all_scores = []\n",
    "    for cat in [\"Identity\", \"Connectivity\", \"Wellness\", \"Prosperity\", \"Finance\"]:\n",
    "        scores_dict = df[f\"{cat}_{cat}_Scores\"].iloc[0]\n",
    "        all_scores.extend(scores_dict.values())\n",
    "    overall_score = sum(all_scores) / len(all_scores) if all_scores else 0\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.bar([\"Overall\"], [overall_score], color='#666666')\n",
    "    plt.title(\"Overall Impact Score\", fontsize=14)\n",
    "    plt.ylabel(\"Score (0-100)\", fontsize=12)\n",
    "    plt.ylim(0, 100)\n",
    "    plt.text(0, overall_score + 2, f\"{overall_score:.1f}\", ha='center')\n",
    "    plt.savefig(\"overall_scores.png\")\n",
    "    plt.close()\n",
    "    print(\"Graphs saved: identity_diversity.png, connectivity_metrics.png, wellness_metrics.png, prosperity_metrics.png, finance_metric.png, category_scores.png, overall_scores.png\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    address = input(\"Enter address: \")\n",
    "    start_time = time.time()\n",
    "    try:\n",
    "        result = automate_impact_tool(address)\n",
    "        print(f\"Completed data collection in {time.time() - start_time:.2f} seconds\")\n",
    "        visualize_data(result)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to process request: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f2030a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using existing nc_county_data.xlsx\n",
      "Calculated medians: {'White (%)': 67.3887521566493, 'Black (%)': 17.767609179573636, 'Hispanic (%)': 6.8423496082637225, 'Foreign Born (%)': 3.8914497825014154, 'Park Access': 1.4966990336264674, 'Bus Stops': 7.483495168132338, 'Transit (%)': 0.07483495168132337, 'Uninsured (%)': 3.074482984159226, 'Provider Ratio': 157.96463166891695, 'Median Income ($)': 51497.0, 'Home Ownership (%)': 28.471411394017153, 'Unemployment (%)': 2.596609445713743, 'Grants Proxy (per 1000)': 8.696259228740153}\n",
      "All county metrics saved to nc_all_county_metrics_winsorized.csv for Tableau visualization\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from geopy.geocoders import Nominatim\n",
    "from geopy.extra.rate_limiter import RateLimiter\n",
    "import pandas as pd\n",
    "import numpy as np  # Added for percentile calculations\n",
    "from census import Census\n",
    "import time\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import statistics\n",
    "import json\n",
    "import unicodedata\n",
    "\n",
    "# Constants\n",
    "CENSUS_API_KEY = \"86cfe7a999f6607864204747a5ac83b7c77e02fb\"\n",
    "RADIUS = 5\n",
    "BASE_YEAR = 2021\n",
    "TIMEOUT = 30\n",
    "MAX_RETRIES = 3\n",
    "\n",
    "geolocator = Nominatim(user_agent=\"impact_tool\")\n",
    "geocode = RateLimiter(geolocator.geocode, min_delay_seconds=1, max_retries=3, error_wait_seconds=5)\n",
    "c = Census(CENSUS_API_KEY, year=BASE_YEAR)\n",
    "census_cache = {}\n",
    "mecklenburg_cache_file = \"mecklenburg_cache.json\"\n",
    "\n",
    "def load_mecklenburg_cache():\n",
    "    try:\n",
    "        if os.path.exists(mecklenburg_cache_file):\n",
    "            with open(mecklenburg_cache_file, 'r') as f:\n",
    "                return json.load(f)\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error reading cache file: {e}. Starting with empty cache.\")\n",
    "        if os.path.exists(mecklenburg_cache_file):\n",
    "            os.remove(mecklenburg_cache_file)\n",
    "    return {}\n",
    "\n",
    "def save_mecklenburg_cache(cache):\n",
    "    try:\n",
    "        with open(mecklenburg_cache_file, 'w') as f:\n",
    "            json.dump(cache, f, default=str)\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving cache: {e}\")\n",
    "\n",
    "def retry_with_backoff(func, *args, max_attempts=MAX_RETRIES, base_delay=1, max_delay=10):\n",
    "    for attempt in range(max_attempts):\n",
    "        try:\n",
    "            return func(*args)\n",
    "        except (requests.RequestException, ValueError) as e:\n",
    "            if attempt == max_attempts - 1:\n",
    "                raise\n",
    "            delay = min(base_delay * (2 ** attempt), max_delay)\n",
    "            print(f\"Attempt {attempt + 1} failed: {e}. Retrying after {delay}s...\")\n",
    "            time.sleep(delay)\n",
    "    raise ValueError(\"Max retries reached\")\n",
    "\n",
    "def geocode_address(address):\n",
    "    def _geocode():\n",
    "        location = geocode(address, timeout=TIMEOUT)\n",
    "        if location:\n",
    "            print(f\"Geocoded {address} to ({location.latitude}, {location.longitude})\")\n",
    "            return location.latitude, location.longitude\n",
    "        raise ValueError(f\"Address not found: {address}\")\n",
    "    return retry_with_backoff(_geocode)\n",
    "\n",
    "def get_county_fips(lat, lon):\n",
    "    def _get_fips():\n",
    "        url = f\"https://geocoding.geo.census.gov/geocoder/geographies/coordinates?x={lon}&y={lat}&benchmark=Public_AR_Current&vintage=Current_Current&format=json\"\n",
    "        response = requests.get(url, timeout=TIMEOUT)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        print(\"Geocoding API response is successful\")\n",
    "        county = data[\"result\"][\"geographies\"][\"Counties\"][0]\n",
    "        state_fips = county[\"GEOID\"][:2]\n",
    "        county_fips = county[\"GEOID\"][-3:]\n",
    "        print(f\"Geocoded to State FIPS: {state_fips}, County FIPS: {county_fips}\")\n",
    "        return state_fips, county_fips\n",
    "    return retry_with_backoff(_get_fips)\n",
    "\n",
    "def fetch_census_data(fields, state_fips, county_fips):\n",
    "    cache_key = f\"{county_fips}_{'_'.join(fields)}\"\n",
    "    meck_cache = load_mecklenburg_cache()\n",
    "    if cache_key in meck_cache:\n",
    "        print(f\"Using Mecklenburg cache for {fields}\")\n",
    "        return meck_cache[cache_key]\n",
    "    if cache_key in census_cache:\n",
    "        print(f\"Using global cache for {fields}\")\n",
    "        return census_cache[cache_key]\n",
    "    def _fetch():\n",
    "        try:\n",
    "            response = c.acs5.state_county(fields, state_fips, county_fips)\n",
    "            print(f\"ACS5 API call successful for fields: {fields}\")\n",
    "            data = response[0] if response else None\n",
    "            if not data:\n",
    "                raise ValueError(\"No data returned from Census API\")\n",
    "            return {k: str(v) for k, v in data.items()}\n",
    "        except Exception as e:\n",
    "            print(f\"Census library error: {e}\")\n",
    "            url = f\"https://api.census.gov/data/{BASE_YEAR}/acs/acs5?get={','.join(fields)}&for=county:{county_fips}&in=state:{state_fips}&key={CENSUS_API_KEY}\"\n",
    "            response = requests.get(url, timeout=TIMEOUT)\n",
    "            response.raise_for_status()\n",
    "            data = response.json()\n",
    "            print(f\"Direct Census API response: {data}\")\n",
    "            data = dict(zip(data[0], data[1])) if len(data) > 1 else None\n",
    "            if not data:\n",
    "                raise ValueError(\"No data returned from direct Census API\")\n",
    "            return {k: str(v) for k, v in data.items()}\n",
    "    data = retry_with_backoff(_fetch)\n",
    "    census_cache[cache_key] = data\n",
    "    if county_fips == \"119\" and state_fips == \"37\":\n",
    "        meck_cache[cache_key] = data\n",
    "        save_mecklenburg_cache(meck_cache)\n",
    "    return data\n",
    "\n",
    "def fetch_nc_county_data(state_fips):\n",
    "    if os.path.exists(\"nc_county_data.xlsx\"):\n",
    "        print(\"Using existing nc_county_data.xlsx\")\n",
    "        return pd.read_excel(\"nc_county_data.xlsx\")\n",
    "    fields = (\"NAME\", \"B03002_003E\", \"B03002_004E\", \"B03002_012E\", \"B05002_013E\", \n",
    "              \"B01001_001E\", \"B08301_010E\", \"B27001_028E\", \"C24050_026E\", \n",
    "              \"B19013_001E\", \"B25003_002E\", \"B23025_005E\", \"C24050_001E\")\n",
    "    nc_data = c.acs5.state_county(fields, state_fips, Census.ALL)\n",
    "    county_data = []\n",
    "    for d in nc_data:\n",
    "        pop = float(d[\"B01001_001E\"])\n",
    "        if pop > 0:\n",
    "            county = {\n",
    "                \"FIPS\": d[\"state\"] + d[\"county\"],\n",
    "                \"Name\": d[\"NAME\"],\n",
    "                \"White (%)\": float(d[\"B03002_003E\"]) / pop * 100,\n",
    "                \"Black (%)\": float(d[\"B03002_004E\"]) / pop * 100,\n",
    "                \"Hispanic (%)\": float(d[\"B03002_012E\"]) / pop * 100,\n",
    "                \"Foreign Born (%)\": float(d[\"B05002_013E\"]) / pop * 100,\n",
    "                \"Transit (%)\": float(d[\"B08301_010E\"]) / pop * 100,\n",
    "                \"Uninsured (%)\": float(d[\"B27001_028E\"]) / pop * 100,\n",
    "                \"Provider Ratio\": pop / float(d[\"C24050_026E\"]) if float(d[\"C24050_026E\"]) > 0 else 1000,\n",
    "                \"Median Income ($)\": float(d[\"B19013_001E\"]),\n",
    "                \"Home Ownership (%)\": float(d[\"B25003_002E\"]) / pop * 100,\n",
    "                \"Unemployment (%)\": float(d[\"B23025_005E\"]) / pop * 100,\n",
    "                \"Grants Proxy (per 1000)\": min(10, (float(d[\"C24050_001E\"]) / pop * 1000) / 50)\n",
    "            }\n",
    "            county[\"Park Access\"] = min(50, county[\"Transit (%)\"] * 20)\n",
    "            county[\"Bus Stops\"] = county[\"Transit (%)\"] * 100\n",
    "            county_data.append(county)\n",
    "    df = pd.DataFrame(county_data)\n",
    "    df.to_excel(\"nc_county_data.xlsx\", index=False)\n",
    "    print(\"Saved county data to nc_county_data.xlsx\")\n",
    "    return df\n",
    "\n",
    "def get_nc_medians():\n",
    "    try:\n",
    "        df = pd.read_excel(\"nc_county_data.xlsx\")\n",
    "        medians = {\n",
    "            \"White (%)\": df[\"White (%)\"].median(),\n",
    "            \"Black (%)\": df[\"Black (%)\"].median(),\n",
    "            \"Hispanic (%)\": df[\"Hispanic (%)\"].median(),\n",
    "            \"Foreign Born (%)\": df[\"Foreign Born (%)\"].median(),\n",
    "            \"Park Access\": df[\"Park Access\"].median(),\n",
    "            \"Bus Stops\": df[\"Bus Stops\"].median(),\n",
    "            \"Transit (%)\": df[\"Transit (%)\"].median(),\n",
    "            \"Uninsured (%)\": df[\"Uninsured (%)\"].median(),\n",
    "            \"Provider Ratio\": df[\"Provider Ratio\"].median(),\n",
    "            \"Median Income ($)\": df[\"Median Income ($)\"].median(),\n",
    "            \"Home Ownership (%)\": df[\"Home Ownership (%)\"].median(),\n",
    "            \"Unemployment (%)\": df[\"Unemployment (%)\"].median(),\n",
    "            \"Grants Proxy (per 1000)\": df[\"Grants Proxy (per 1000)\"].median()\n",
    "        }\n",
    "        print(f\"Calculated medians: {medians}\")\n",
    "        return medians\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading Excel: {e}, using fallback medians\")\n",
    "        return {\n",
    "            \"White (%)\": 60, \"Black (%)\": 20, \"Hispanic (%)\": 8, \"Foreign Born (%)\": 7,\n",
    "            \"Park Access\": 10, \"Bus Stops\": 50, \"Transit (%)\": 0.5,\n",
    "            \"Uninsured (%)\": 5, \"Provider Ratio\": 150,\n",
    "            \"Median Income ($)\": 55000, \"Home Ownership (%)\": 40, \"Unemployment (%)\": 4,\n",
    "            \"Grants Proxy (per 1000)\": 7\n",
    "        }\n",
    "\n",
    "def clean_string(text):\n",
    "    \"\"\"Clean string to ensure UTF-8 compatibility.\"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        text = str(text)\n",
    "    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('ascii')\n",
    "    return text\n",
    "\n",
    "def calculate_all_metrics(state_fips):\n",
    "    # Load NC county data\n",
    "    try:\n",
    "        df = fetch_nc_county_data(state_fips)\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching county data: {e}\")\n",
    "        return\n",
    "\n",
    "    # Convert FIPS to string to handle indexing\n",
    "    df[\"FIPS\"] = df[\"FIPS\"].astype(str)\n",
    "\n",
    "    # Get NC medians\n",
    "    medians = get_nc_medians()\n",
    "\n",
    "    # Calculate Winsorized Min/Max (5th and 95th percentiles)\n",
    "    mins = {\n",
    "        \"White (%)\": np.percentile(df[\"White (%)\"], 5),\n",
    "        \"Black (%)\": np.percentile(df[\"Black (%)\"], 5),\n",
    "        \"Hispanic (%)\": np.percentile(df[\"Hispanic (%)\"], 5),\n",
    "        \"Foreign Born (%)\": np.percentile(df[\"Foreign Born (%)\"], 5),\n",
    "        \"Park Access\": np.percentile(df[\"Park Access\"], 5),\n",
    "        \"Bus Stops\": np.percentile(df[\"Bus Stops\"], 5),\n",
    "        \"Transit (%)\": np.percentile(df[\"Transit (%)\"], 5),\n",
    "        \"Uninsured (%)\": np.percentile(df[\"Uninsured (%)\"], 5),\n",
    "        \"Provider Ratio\": np.percentile(df[\"Provider Ratio\"], 5),\n",
    "        \"Median Income ($)\": np.percentile(df[\"Median Income ($)\"], 5),\n",
    "        \"Home Ownership (%)\": np.percentile(df[\"Home Ownership (%)\"], 5),\n",
    "        \"Unemployment (%)\": np.percentile(df[\"Unemployment (%)\"], 5),\n",
    "        \"Grants Proxy (per 1000)\": np.percentile(df[\"Grants Proxy (per 1000)\"], 5)\n",
    "    }\n",
    "    maxs = {\n",
    "        \"White (%)\": np.percentile(df[\"White (%)\"], 95),\n",
    "        \"Black (%)\": np.percentile(df[\"Black (%)\"], 95),\n",
    "        \"Hispanic (%)\": np.percentile(df[\"Hispanic (%)\"], 95),\n",
    "        \"Foreign Born (%)\": np.percentile(df[\"Foreign Born (%)\"], 95),\n",
    "        \"Park Access\": np.percentile(df[\"Park Access\"], 95),\n",
    "        \"Bus Stops\": np.percentile(df[\"Bus Stops\"], 95),\n",
    "        \"Transit (%)\": np.percentile(df[\"Transit (%)\"], 95),\n",
    "        \"Uninsured (%)\": np.percentile(df[\"Uninsured (%)\"], 95),\n",
    "        \"Provider Ratio\": np.percentile(df[\"Provider Ratio\"], 95),\n",
    "        \"Median Income ($)\": np.percentile(df[\"Median Income ($)\"], 95),\n",
    "        \"Home Ownership (%)\": np.percentile(df[\"Home Ownership (%)\"], 95),\n",
    "        \"Unemployment (%)\": np.percentile(df[\"Unemployment (%)\"], 95),\n",
    "        \"Grants Proxy (per 1000)\": np.percentile(df[\"Grants Proxy (per 1000)\"], 95)\n",
    "    }\n",
    "\n",
    "    # Calculate state scores (normalize the medians)\n",
    "    state_scores = {}\n",
    "    for metric in medians:\n",
    "        clipped_value = np.clip(medians[metric], mins[metric], maxs[metric])\n",
    "        if maxs[metric] == mins[metric]:  # Avoid division by zero\n",
    "            normalized_score = 50.0  # If min == max, assign a neutral score\n",
    "        else:\n",
    "            normalized_score = (clipped_value - mins[metric]) / (maxs[metric] - mins[metric]) * 100\n",
    "        # Adjust for directionality\n",
    "        if metric in [\"White (%)\", \"Uninsured (%)\", \"Provider Ratio\", \"Unemployment (%)\"]:  # Lower is better\n",
    "            state_scores[f\"{metric} Score\"] = 100 - normalized_score\n",
    "        else:  # Higher is better\n",
    "            state_scores[f\"{metric} Score\"] = normalized_score\n",
    "\n",
    "    # Initialize results\n",
    "    results = []\n",
    "\n",
    "    # Process each county\n",
    "    for _, row in df.iterrows():\n",
    "        county_name = clean_string(row[\"Name\"])\n",
    "        county_fips = row[\"FIPS\"][-3:] if len(row[\"FIPS\"]) >= 5 else row[\"FIPS\"]\n",
    "\n",
    "        # Identity Metrics\n",
    "        identity = {\n",
    "            \"White (%)\": float(row[\"White (%)\"]) if pd.notna(row[\"White (%)\"]) else 0.0,\n",
    "            \"Black (%)\": float(row[\"Black (%)\"]) if pd.notna(row[\"Black (%)\"]) else 0.0,\n",
    "            \"Hispanic (%)\": float(row[\"Hispanic (%)\"]) if pd.notna(row[\"Hispanic (%)\"]) else 0.0,\n",
    "            \"Foreign Born (%)\": float(row[\"Foreign Born (%)\"]) if pd.notna(row[\"Foreign Born (%)\"]) else 0.0\n",
    "        }\n",
    "        identity_scores = {}\n",
    "        identity_diffs = {}\n",
    "        for metric in identity:\n",
    "            clipped_value = np.clip(identity[metric], mins[metric], maxs[metric])\n",
    "            if maxs[metric] == mins[metric]:  # Avoid division by zero\n",
    "                score = 50.0\n",
    "            else:\n",
    "                score = (clipped_value - mins[metric]) / (maxs[metric] - mins[metric]) * 100\n",
    "            if metric == \"White (%)\":  # Lower is better\n",
    "                score = 100 - score\n",
    "            identity_scores[f\"{metric} Score\"] = score\n",
    "            identity_diffs[f\"{metric} Diff\"] = round(score - state_scores[f\"{metric} Score\"], 2)\n",
    "\n",
    "        identity_score = sum(identity_scores.values()) / len(identity_scores) if identity_scores else 0\n",
    "        state_identity_score = sum(state_scores[f\"{metric} Score\"] for metric in identity) / len(identity)\n",
    "        identity_diff = round(identity_score - state_identity_score, 2)\n",
    "\n",
    "        # Connectivity Metrics\n",
    "        connectivity = {\n",
    "            \"Park Access\": float(row[\"Park Access\"]) if pd.notna(row[\"Park Access\"]) else 0.0,\n",
    "            \"Bus Stops\": float(row[\"Bus Stops\"]) if pd.notna(row[\"Bus Stops\"]) else 0.0,\n",
    "            \"Transit (%)\": float(row[\"Transit (%)\"]) if pd.notna(row[\"Transit (%)\"]) else 0.0\n",
    "        }\n",
    "        connectivity_scores = {}\n",
    "        connectivity_diffs = {}\n",
    "        for metric in connectivity:\n",
    "            clipped_value = np.clip(connectivity[metric], mins[metric], maxs[metric])\n",
    "            if maxs[metric] == mins[metric]:\n",
    "                score = 50.0\n",
    "            else:\n",
    "                score = (clipped_value - mins[metric]) / (maxs[metric] - mins[metric]) * 100\n",
    "            connectivity_scores[f\"{metric} Score\"] = score\n",
    "            connectivity_diffs[f\"{metric} Diff\"] = round(score - state_scores[f\"{metric} Score\"], 2)\n",
    "\n",
    "        connectivity_score = sum(connectivity_scores.values()) / len(connectivity_scores) if connectivity_scores else 0\n",
    "        state_connectivity_score = sum(state_scores[f\"{metric} Score\"] for metric in connectivity) / len(connectivity)\n",
    "        connectivity_diff = round(connectivity_score - state_connectivity_score, 2)\n",
    "\n",
    "        # Wellness Metrics\n",
    "        wellness = {\n",
    "            \"Uninsured (%)\": float(row[\"Uninsured (%)\"]) if pd.notna(row[\"Uninsured (%)\"]) else 0.0,\n",
    "            \"Provider Ratio\": float(row[\"Provider Ratio\"]) if pd.notna(row[\"Provider Ratio\"]) else 0.0\n",
    "        }\n",
    "        wellness_scores = {}\n",
    "        wellness_diffs = {}\n",
    "        for metric in wellness:\n",
    "            clipped_value = np.clip(wellness[metric], mins[metric], maxs[metric])\n",
    "            if maxs[metric] == mins[metric]:\n",
    "                score = 50.0\n",
    "            else:\n",
    "                score = (clipped_value - mins[metric]) / (maxs[metric] - mins[metric]) * 100\n",
    "            if metric in [\"Uninsured (%)\", \"Provider Ratio\"]:  # Lower is better\n",
    "                score = 100 - score\n",
    "            wellness_scores[f\"{metric} Score\"] = score\n",
    "            wellness_diffs[f\"{metric} Diff\"] = round(score - state_scores[f\"{metric} Score\"], 2)\n",
    "\n",
    "        wellness_score = sum(wellness_scores.values()) / len(wellness_scores) if wellness_scores else 0\n",
    "        state_wellness_score = sum(state_scores[f\"{metric} Score\"] for metric in wellness) / len(wellness)\n",
    "        wellness_diff = round(wellness_score - state_wellness_score, 2)\n",
    "\n",
    "        # Prosperity Metrics\n",
    "        prosperity = {\n",
    "            \"Median Income ($)\": float(row[\"Median Income ($)\"]) if pd.notna(row[\"Median Income ($)\"]) else 0.0,\n",
    "            \"Home Ownership (%)\": float(row[\"Home Ownership (%)\"]) if pd.notna(row[\"Home Ownership (%)\"]) else 0.0,\n",
    "            \"Unemployment (%)\": float(row[\"Unemployment (%)\"]) if pd.notna(row[\"Unemployment (%)\"]) else 0.0\n",
    "        }\n",
    "        prosperity_scores = {}\n",
    "        prosperity_diffs = {}\n",
    "        for metric in prosperity:\n",
    "            clipped_value = np.clip(prosperity[metric], mins[metric], maxs[metric])\n",
    "            if maxs[metric] == mins[metric]:\n",
    "                score = 50.0\n",
    "            else:\n",
    "                score = (clipped_value - mins[metric]) / (maxs[metric] - mins[metric]) * 100\n",
    "            if metric == \"Unemployment (%)\":  # Lower is better\n",
    "                score = 100 - score\n",
    "            prosperity_scores[f\"{metric} Score\"] = score\n",
    "            prosperity_diffs[f\"{metric} Diff\"] = round(score - state_scores[f\"{metric} Score\"], 2)\n",
    "\n",
    "        prosperity_score = sum(prosperity_scores.values()) / len(prosperity_scores) if prosperity_scores else 0\n",
    "        state_prosperity_score = sum(state_scores[f\"{metric} Score\"] for metric in prosperity) / len(prosperity)\n",
    "        prosperity_diff = round(prosperity_score - state_prosperity_score, 2)\n",
    "\n",
    "        # Finance Metrics\n",
    "        finance = {\n",
    "            \"Grants Proxy (per 1000)\": float(row[\"Grants Proxy (per 1000)\"]) if pd.notna(row[\"Grants Proxy (per 1000)\"]) else 0.0\n",
    "        }\n",
    "        finance_scores = {}\n",
    "        finance_diffs = {}\n",
    "        for metric in finance:\n",
    "            clipped_value = np.clip(finance[metric], mins[metric], maxs[metric])\n",
    "            if maxs[metric] == mins[metric]:\n",
    "                score = 50.0\n",
    "            else:\n",
    "                score = (clipped_value - mins[metric]) / (maxs[metric] - mins[metric]) * 100\n",
    "            finance_scores[f\"{metric} Score\"] = score\n",
    "            finance_diffs[f\"{metric} Diff\"] = round(score - state_scores[f\"{metric} Score\"], 2)\n",
    "\n",
    "        finance_score = finance_scores[\"Grants Proxy (per 1000) Score\"]\n",
    "        state_finance_score = state_scores[\"Grants Proxy (per 1000) Score\"]\n",
    "        finance_diff = round(finance_score - state_finance_score, 2)\n",
    "\n",
    "        # Overall Score\n",
    "        all_scores = list(identity_scores.values()) + list(connectivity_scores.values()) + list(wellness_scores.values()) + list(prosperity_scores.values()) + list(finance_scores.values())\n",
    "        overall_score = sum(all_scores) / len(all_scores) if all_scores else 0\n",
    "        all_state_scores = list(state_scores.values())\n",
    "        overall_state_score = sum(all_state_scores) / len(all_state_scores) if all_state_scores else 0\n",
    "        overall_diff = round(overall_score - overall_state_score, 2)\n",
    "\n",
    "        # Append flattened results\n",
    "        result = {\n",
    "            \"County\": county_name,\n",
    "            \"FIPS\": row[\"FIPS\"],\n",
    "            \"White (%)\": identity[\"White (%)\"],\n",
    "            \"Black (%)\": identity[\"Black (%)\"],\n",
    "            \"Hispanic (%)\": identity[\"Hispanic (%)\"],\n",
    "            \"Foreign Born (%)\": identity[\"Foreign Born (%)\"],\n",
    "            \"White Score\": round(identity_scores[\"White (%) Score\"], 2),\n",
    "            \"Black Score\": round(identity_scores[\"Black (%) Score\"], 2),\n",
    "            \"Hispanic Score\": round(identity_scores[\"Hispanic (%) Score\"], 2),\n",
    "            \"Foreign Born Score\": round(identity_scores[\"Foreign Born (%) Score\"], 2),\n",
    "            \"White Diff\": identity_diffs[\"White (%) Diff\"],\n",
    "            \"Black Diff\": identity_diffs[\"Black (%) Diff\"],\n",
    "            \"Hispanic Diff\": identity_diffs[\"Hispanic (%) Diff\"],\n",
    "            \"Foreign Born Diff\": identity_diffs[\"Foreign Born (%) Diff\"],\n",
    "            \"Identity Score\": round(identity_score, 2),\n",
    "            \"Identity Diff\": identity_diff,\n",
    "            \"Park Access (%)\": connectivity[\"Park Access\"],\n",
    "            \"Bus Stops\": connectivity[\"Bus Stops\"],\n",
    "            \"Transit (%)\": connectivity[\"Transit (%)\"],\n",
    "            \"Park Access Score\": round(connectivity_scores[\"Park Access Score\"], 2),\n",
    "            \"Bus Stops Score\": round(connectivity_scores[\"Bus Stops Score\"], 2),\n",
    "            \"Transit Score\": round(connectivity_scores[\"Transit (%) Score\"], 2),\n",
    "            \"Park Access Diff\": connectivity_diffs[\"Park Access Diff\"],\n",
    "            \"Bus Stops Diff\": connectivity_diffs[\"Bus Stops Diff\"],\n",
    "            \"Transit Diff\": connectivity_diffs[\"Transit (%) Diff\"],\n",
    "            \"Connectivity Score\": round(connectivity_score, 2),\n",
    "            \"Connectivity Diff\": connectivity_diff,\n",
    "            \"Uninsured (%)\": wellness[\"Uninsured (%)\"],\n",
    "            \"Provider Ratio\": wellness[\"Provider Ratio\"],\n",
    "            \"Uninsured Score\": round(wellness_scores[\"Uninsured (%) Score\"], 2),\n",
    "            \"Provider Ratio Score\": round(wellness_scores[\"Provider Ratio Score\"], 2),\n",
    "            \"Uninsured Diff\": wellness_diffs[\"Uninsured (%) Diff\"],\n",
    "            \"Provider Ratio Diff\": wellness_diffs[\"Provider Ratio Diff\"],\n",
    "            \"Wellness Score\": round(wellness_score, 2),\n",
    "            \"Wellness Diff\": wellness_diff,\n",
    "            \"Median Income ($)\": prosperity[\"Median Income ($)\"],\n",
    "            \"Home Ownership (%)\": prosperity[\"Home Ownership (%)\"],\n",
    "            \"Unemployment (%)\": prosperity[\"Unemployment (%)\"],\n",
    "            \"Median Income Score\": round(prosperity_scores[\"Median Income ($) Score\"], 2),\n",
    "            \"Home Ownership Score\": round(prosperity_scores[\"Home Ownership (%) Score\"], 2),\n",
    "            \"Unemployment Score\": round(prosperity_scores[\"Unemployment (%) Score\"], 2),\n",
    "            \"Median Income Diff\": prosperity_diffs[\"Median Income ($) Diff\"],\n",
    "            \"Home Ownership Diff\": prosperity_diffs[\"Home Ownership (%) Diff\"],\n",
    "            \"Unemployment Diff\": prosperity_diffs[\"Unemployment (%) Diff\"],\n",
    "            \"Prosperity Score\": round(prosperity_score, 2),\n",
    "            \"Prosperity Diff\": prosperity_diff,\n",
    "            \"Grants Proxy (per 1000)\": finance[\"Grants Proxy (per 1000)\"],\n",
    "            \"Grants Proxy Score\": round(finance_scores[\"Grants Proxy (per 1000) Score\"], 2),\n",
    "            \"Grants Proxy Diff\": finance_diffs[\"Grants Proxy (per 1000) Diff\"],\n",
    "            \"Finance Score\": round(finance_score, 2),\n",
    "            \"Finance Diff\": finance_diff,\n",
    "            \"Overall Score\": round(overall_score, 2),\n",
    "            \"Overall Diff\": overall_diff\n",
    "        }\n",
    "        results.append(result)\n",
    "\n",
    "    # Create DataFrame\n",
    "    result_df = pd.DataFrame(results)\n",
    "    \n",
    "    # Replace any NaN values\n",
    "    result_df = result_df.fillna(0.0)\n",
    "    \n",
    "    # Sort by Overall Score (descending)\n",
    "    result_df = result_df.sort_values(by=\"Overall Score\", ascending=False)\n",
    "    \n",
    "    # Save to CSV for Tableau\n",
    "    output_file = \"nc_all_county_metrics_winsorized.csv\"\n",
    "    try:\n",
    "        result_df.to_csv(output_file, index=False, encoding='utf-8')\n",
    "        print(f\"All county metrics saved to {output_file} for Tableau visualization\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving to CSV: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Run for North Carolina (state FIPS 37)\n",
    "    calculate_all_metrics(\"37\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42f44ee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Data Preview:\n",
      "                               County   FIPS  White (%)  Black (%)  \\\n",
      "0       Durham County, North Carolina  37063  42.564642  34.825361   \n",
      "1  Mecklenburg County, North Carolina  37119  45.586766  31.008171   \n",
      "2     Cabarrus County, North Carolina  37025  62.563291  18.609855   \n",
      "3         Wake County, North Carolina  37183  58.803127  19.434118   \n",
      "4       Orange County, North Carolina  37135  68.900635  10.743269   \n",
      "\n",
      "   Hispanic (%)  Foreign Born (%)  White Score  Black Score  Hispanic Score  \\\n",
      "0     13.704060         14.310971        90.94        69.80           94.41   \n",
      "1     13.675585         15.951095        85.33        61.94           94.16   \n",
      "2     10.997288          8.523960        53.78        36.40           70.87   \n",
      "3     10.310967         13.479045        60.77        38.10           64.91   \n",
      "4      8.600451         12.597031        42.01        20.19           50.04   \n",
      "\n",
      "   Foreign Born Score  ...  Unemployment Diff  Prosperity Score  \\\n",
      "0              100.00  ...               1.77             47.91   \n",
      "1              100.00  ...              -0.55             51.24   \n",
      "2               73.73  ...              -3.02             59.21   \n",
      "3              100.00  ...               8.23             62.13   \n",
      "4              100.00  ...              13.13             61.71   \n",
      "\n",
      "   Prosperity Diff  Grants Proxy (per 1000)  Grants Proxy Score  \\\n",
      "0            -1.02                10.000000              100.00   \n",
      "1             2.31                10.000000              100.00   \n",
      "2            10.28                10.000000              100.00   \n",
      "3            13.20                10.000000              100.00   \n",
      "4            12.78                 9.854929               94.61   \n",
      "\n",
      "   Grants Proxy Diff  Finance Score  Finance Diff  Overall Score  Overall Diff  \n",
      "0              48.43         100.00         48.43          84.10         44.34  \n",
      "1              48.43         100.00         48.43          84.10         44.33  \n",
      "2              48.43         100.00         48.43          77.06         37.29  \n",
      "3              48.43         100.00         48.43          76.56         36.79  \n",
      "4              43.04          94.61         43.04          75.15         35.39  \n",
      "\n",
      "[5 rows x 53 columns]\n",
      "\n",
      "Missing Values:\n",
      "County                     0\n",
      "FIPS                       0\n",
      "White (%)                  0\n",
      "Black (%)                  0\n",
      "Hispanic (%)               0\n",
      "Foreign Born (%)           0\n",
      "White Score                0\n",
      "Black Score                0\n",
      "Hispanic Score             0\n",
      "Foreign Born Score         0\n",
      "White Diff                 0\n",
      "Black Diff                 0\n",
      "Hispanic Diff              0\n",
      "Foreign Born Diff          0\n",
      "Identity Score             0\n",
      "Identity Diff              0\n",
      "Park Access (%)            0\n",
      "Bus Stops                  0\n",
      "Transit (%)                0\n",
      "Park Access Score          0\n",
      "Bus Stops Score            0\n",
      "Transit Score              0\n",
      "Park Access Diff           0\n",
      "Bus Stops Diff             0\n",
      "Transit Diff               0\n",
      "Connectivity Score         0\n",
      "Connectivity Diff          0\n",
      "Uninsured (%)              0\n",
      "Provider Ratio             0\n",
      "Uninsured Score            0\n",
      "Provider Ratio Score       0\n",
      "Uninsured Diff             0\n",
      "Provider Ratio Diff        0\n",
      "Wellness Score             0\n",
      "Wellness Diff              0\n",
      "Median Income ($)          0\n",
      "Home Ownership (%)         0\n",
      "Unemployment (%)           0\n",
      "Median Income Score        0\n",
      "Home Ownership Score       0\n",
      "Unemployment Score         0\n",
      "Median Income Diff         0\n",
      "Home Ownership Diff        0\n",
      "Unemployment Diff          0\n",
      "Prosperity Score           0\n",
      "Prosperity Diff            0\n",
      "Grants Proxy (per 1000)    0\n",
      "Grants Proxy Score         0\n",
      "Grants Proxy Diff          0\n",
      "Finance Score              0\n",
      "Finance Diff               0\n",
      "Overall Score              0\n",
      "Overall Diff               0\n",
      "dtype: int64\n",
      "\n",
      "Data Types:\n",
      "County                      object\n",
      "FIPS                        object\n",
      "White (%)                  float64\n",
      "Black (%)                  float64\n",
      "Hispanic (%)               float64\n",
      "Foreign Born (%)           float64\n",
      "White Score                float64\n",
      "Black Score                float64\n",
      "Hispanic Score             float64\n",
      "Foreign Born Score         float64\n",
      "White Diff                 float64\n",
      "Black Diff                 float64\n",
      "Hispanic Diff              float64\n",
      "Foreign Born Diff          float64\n",
      "Identity Score             float64\n",
      "Identity Diff              float64\n",
      "Park Access (%)            float64\n",
      "Bus Stops                  float64\n",
      "Transit (%)                float64\n",
      "Park Access Score          float64\n",
      "Bus Stops Score            float64\n",
      "Transit Score              float64\n",
      "Park Access Diff           float64\n",
      "Bus Stops Diff             float64\n",
      "Transit Diff               float64\n",
      "Connectivity Score         float64\n",
      "Connectivity Diff          float64\n",
      "Uninsured (%)              float64\n",
      "Provider Ratio             float64\n",
      "Uninsured Score            float64\n",
      "Provider Ratio Score       float64\n",
      "Uninsured Diff             float64\n",
      "Provider Ratio Diff        float64\n",
      "Wellness Score             float64\n",
      "Wellness Diff              float64\n",
      "Median Income ($)          float64\n",
      "Home Ownership (%)         float64\n",
      "Unemployment (%)           float64\n",
      "Median Income Score        float64\n",
      "Home Ownership Score       float64\n",
      "Unemployment Score         float64\n",
      "Median Income Diff         float64\n",
      "Home Ownership Diff        float64\n",
      "Unemployment Diff          float64\n",
      "Prosperity Score           float64\n",
      "Prosperity Diff            float64\n",
      "Grants Proxy (per 1000)    float64\n",
      "Grants Proxy Score         float64\n",
      "Grants Proxy Diff          float64\n",
      "Finance Score              float64\n",
      "Finance Diff               float64\n",
      "Overall Score              float64\n",
      "Overall Diff               float64\n",
      "dtype: object\n",
      "\n",
      "Number of Duplicate Rows: 0\n",
      "\n",
      "Cleaned dataset saved to: nc_county_metrics_cleaned.csv\n",
      "\n",
      "Cleaned Data Preview:\n",
      "                               County   FIPS  White (%)  Black (%)  \\\n",
      "0       Durham County, North Carolina  37063  42.564642  34.825361   \n",
      "1  Mecklenburg County, North Carolina  37119  45.586766  31.008171   \n",
      "2     Cabarrus County, North Carolina  37025  62.563291  18.609855   \n",
      "3         Wake County, North Carolina  37183  58.803127  19.434118   \n",
      "4       Orange County, North Carolina  37135  68.900635  10.743269   \n",
      "\n",
      "   Hispanic (%)  Foreign Born (%)  White Score  Black Score  Hispanic Score  \\\n",
      "0     13.704060         14.310971        90.94        69.80           94.41   \n",
      "1     13.675585         15.951095        85.33        61.94           94.16   \n",
      "2     10.997288          8.523960        53.78        36.40           70.87   \n",
      "3     10.310967         13.479045        60.77        38.10           64.91   \n",
      "4      8.600451         12.597031        42.01        20.19           50.04   \n",
      "\n",
      "   Foreign Born Score  ...  Unemployment Diff  Prosperity Score  \\\n",
      "0              100.00  ...               1.77             47.91   \n",
      "1              100.00  ...              -0.55             51.24   \n",
      "2               73.73  ...              -3.02             59.21   \n",
      "3              100.00  ...               8.23             62.13   \n",
      "4              100.00  ...              13.13             61.71   \n",
      "\n",
      "   Prosperity Diff  Grants Proxy (per 1000)  Grants Proxy Score  \\\n",
      "0            -1.02                10.000000              100.00   \n",
      "1             2.31                10.000000              100.00   \n",
      "2            10.28                10.000000              100.00   \n",
      "3            13.20                10.000000              100.00   \n",
      "4            12.78                 9.854929               94.61   \n",
      "\n",
      "   Grants Proxy Diff  Finance Score  Finance Diff  Overall Score  Overall Diff  \n",
      "0              48.43         100.00         48.43          84.10         44.34  \n",
      "1              48.43         100.00         48.43          84.10         44.33  \n",
      "2              48.43         100.00         48.43          77.06         37.29  \n",
      "3              48.43         100.00         48.43          76.56         36.79  \n",
      "4              43.04          94.61         43.04          75.15         35.39  \n",
      "\n",
      "[5 rows x 53 columns]\n"
     ]
    }
   ],
   "source": [
    "# Import the required library\n",
    "import pandas as pd\n",
    "\n",
    "# Step 1: Load the dataset\n",
    "# Replace 'nc_all_county_metrics_winsorized.csv' with the path to your file if it's not in the same directory\n",
    "df = pd.read_csv('nc_all_county_metrics_winsorized.csv')\n",
    "\n",
    "# Step 2: Display the first few rows to inspect the data\n",
    "print(\"Initial Data Preview:\")\n",
    "print(df.head())\n",
    "\n",
    "# Step 3: Clean the 'County' column by removing quotes\n",
    "# The County column has values like \"Durham County, North Carolina\" with quotes, which we need to remove\n",
    "df['County'] = df['County'].str.strip('\"')\n",
    "\n",
    "# Step 4: Check for missing values\n",
    "print(\"\\nMissing Values:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Step 5: Ensure proper data types\n",
    "# Most columns should be numeric (floats/ints), except for 'County' and 'FIPS' which should be strings\n",
    "# Convert 'FIPS' to string to preserve leading zeros (important for Tableau's geographic mapping)\n",
    "df['FIPS'] = df['FIPS'].astype(str).str.zfill(5)  # Ensure FIPS is 5 digits with leading zeros\n",
    "\n",
    "# Verify data types\n",
    "print(\"\\nData Types:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "# Step 6: Check for any duplicate rows\n",
    "print(\"\\nNumber of Duplicate Rows:\", df.duplicated().sum())\n",
    "\n",
    "# Step 7: Save the cleaned dataset to a new CSV file for Tableau\n",
    "cleaned_file_path = 'nc_county_metrics_cleaned.csv'\n",
    "df.to_csv(cleaned_file_path, index=False)\n",
    "print(f\"\\nCleaned dataset saved to: {cleaned_file_path}\")\n",
    "\n",
    "# Step 8: Display the first few rows of the cleaned dataset\n",
    "print(\"\\nCleaned Data Preview:\")\n",
    "print(df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
